[
  {
    "question": "W grze w naśladownictwo rozważanej przez Turinga bierze udział:",
    "options": [
      "1 gracz i 1 pytający",
      "2 graczy i 1 pytający",
      "2 graczy",
      "2 graczy i 2 pytających"
    ],
    "correct": [
      "2 graczy i 1 pytający"
    ]
  },
  {
    "question": "„Gra w życie” Conwaya jest przykładem:",
    "options": [
      "testu Turinga",
      "problemu rozpoznawania wzorców",
      "dwuwymiarowego automatu komórkowego",
      "problemu optymalizacji"
    ],
    "correct": [
      "dwuwymiarowego automatu komórkowego"
    ]
  },
  {
    "question": "Przez analogię do gry „kółko i krzyżyk” o szachach można powiedzieć, że:",
    "options": [
      "są grą nieskończoną, ale rozwiązywalną",
      "są grą skończoną, więc rozwiązywalną",
      "są grą skończoną, ale nierozwiązywalną",
      "są grą nieskończoną, więc nierozwiązywalną"
    ],
    "correct": [
      "są grą skończoną, więc rozwiązywalną"
    ]
  },
  {
    "question": "Algorytm Breadth-first search zanim może odwiedzić węzeł o głębokości d musi najpierw:",
    "options": [
      "sprawdzić, czy zbiór Open jest pusty",
      "sprawdzić, czy zbiór Closed jest pusty",
      "odwiedzić wszystkie węzły o głębokości d-1",
      "odwiedzić wszystkie węzły o głębokości d+1"
    ],
    "correct": [
      "odwiedzić wszystkie węzły o głębokości d-1"
    ]
  },
  {
    "question": "Algorytmy Breadth-first search i Depth-first search należą do grupy algorytmów przechodzenia grafu w sposób:",
    "options": [
      "heurystyczny",
      "nieinformacyjny",
      "zachłanny",
      "przypadkowy"
    ],
    "correct": [
      "nieinformacyjny"
    ]
  },
  {
    "question": "Algorytm Dijkstry w każdym węźle (stanie) wykorzystuje tylko informację o:",
    "options": [
      "dokładnej przebytej odległości od węzła początkowego",
      "dokładnej odległości pozostałej do węzła końcowego",
      "szacowanej odległości do węzła końcowego",
      "szacowanej przebytej odległości od węzła początkowego"
    ],
    "correct": [
      "dokładnej przebytej odległości od węzła początkowego"
    ]
  },
  {
    "question": "Realizacja zbioru Open za pomocą kopca binarnego powoduje, że pobranie elementu minimalnego oraz włożenie nowego elementu są o złożonościach odpowiednio:",
    "options": [
      "O(1) i O(logn)",
      "O(1) i O(1)",
      "O(logn) i O(logn)",
      "O(logn) i O(1)"
    ],
    "correct": [
      "O(logn) i O(logn)"
    ]
  },
  {
    "question": "Podmiana (aktualizacja) pewnego stanu w zbiorze Open, realizowanego za pomocą kopca binarnego, wymaga w ogólności kosztu:",
    "options": [
      "O(logn)",
      "O(n²)",
      "O(n)",
      "O(n logn)"
    ],
    "correct": [
      "O(n)"
    ]
  },
  {
    "question": "Realizacja zbioru Closed za pomocą mapy haszującej pozwala na operacje odczytywania i dodawania elementów o złożonościach odpowiednio:",
    "options": [
      "liniowej i stałej",
      "stałej i zamortyzowanej stałej",
      "stałej i stałej",
      "zamortyzowanej stałej i liniowej"
    ],
    "correct": [
      "stałej i zamortyzowanej stałej"
    ]
  },
  {
    "question": "Algorytm Best-first search jest:",
    "options": [
      "ogólniejszym algorytmem od Breadth-first search",
      "ogólniejszym algorytmem od Depth-first search",
      "szczególnym przypadkiem algorytmu Dijkstry",
      "szczególnym przypadkiem algorytmu A*"
    ],
    "correct": [
      "szczególnym przypadkiem algorytmu A*"
    ]
  },
  {
    "question": "Funkcje heurystyczne używane w algorytmach Best-first search mają za zadanie określać atrakcyjność stanu za pomocą jego:",
    "options": [
      "bliskości do stanu docelowego",
      "szacowanej sumy nagród wzdłuż pozostałej ścieżki",
      "odległości od stanu początkowego",
      "sumy nagród zebranej wzdłuż ścieżki"
    ],
    "correct": [
      "bliskości do stanu docelowego"
    ]
  },
  {
    "question": "Heurystyka dopuszczalna to taka, dla której dla wszystkich par s, t zachodzi:",
    "options": [
      "h(s) ≤ h(t)",
      "h(s) ≥ d(s,t) + h(t)",
      "g(s) + h(s) ≤ g(t) + h(t)",
      "ƒ(s) ≥ ƒ(t)"
    ],
    "correct": [
      "g(s) + h(s) ≤ g(t) + h(t)"
    ]
  },
  {
    "question": "W układance 'puzzle przesuwne' heurystyka Manhattan:",
    "options": [
      "jest mniej dokładna niż heurystyka Misplaced Tiles",
      "jest równa odległości Manhattan kostki pustej do jej miejsca docelowego",
      "jest równa odległości Manhattan kostki n²-1 do jej miejsca docelowego",
      "jest równa sumie odległości Manhattan wszystkich kostek o numerach {1,2,..., n²-1} do ich miejsc docelowych"
    ],
    "correct": [
      "jest równa sumie odległości Manhattan wszystkich kostek o numerach {1,2,..., n²-1} do ich miejsc docelowych"
    ]
  },
  {
    "question": "Dla każdego stanu s prawdziwe są nierówności:",
    "options": [
      "h3(s) ≤ h2(s) ≤ h1(s)",
      "h1(s) ≤ h3(s) ≤ h2(s)",
      "h2(s) ≤ h3(s) ≤ h1(s)",
      "h1(s) ≤ h2(s) ≤ h3(s)"
    ],
    "correct": [
      "h1(s) ≤ h2(s) ≤ h3(s)"
    ]
  },
  {
    "question": "W przeszukiwaniu drzew gier dwuosobowych algorytm MIN-MAX przegląda:",
    "options": [
      "możliwie najmniej stanów",
      "przynajmniej tyle stanów, co 'przycinanie α-β'",
      "co najwyżej tyle stanów, co 'przycinanie α-β'",
      "stany wg rosnącej głębokości"
    ],
    "correct": [
      "przynajmniej tyle stanów, co 'przycinanie α-β'"
    ]
  },
  {
    "question": "Algorytm 'przycinanie α-β' odwiedzi pewien stan, jeżeli aktualnie spełniona jest zależność:",
    "options": [
      "α < β",
      "α ≤ β",
      "α > β",
      "α ≥ β"
    ],
    "correct": [
      "α < β"
    ]
  },
  {
    "question": "Optymistyczna złożoność 'przycinania α-β' jest rzędu:",
    "options": [
      "O(√(b^D))",
      "O(b^√D)",
      "O(b^D)",
      "O(b^D)"
    ],
    "correct": [
      "O(√(b^D))"
    ]
  },
  {
    "question": "Heurystyka materialna stosowana dla szachów oznacza:",
    "options": [
      "liczbę ruchów potrzebną do zadania mata",
      "liczbę ruchów potrzebną do dojścia do pola przemiany",
      "różnicę pomiędzy sumą wartości pozostałych bierek białych i czarnych",
      "różnicę pomiędzy sumą wartości zbitych bierek białych i czarnych"
    ],
    "correct": [
      "różnicę pomiędzy sumą wartości pozostałych bierek białych i czarnych"
    ]
  },
  {
    "question": "W perceptronie prostym wzór na poprawkę wag można zapisać wzorem:",
    "options": [
      "w(k+1) := w(k) + η yᵢ xᵢ",
      "w(k+1) := w(k) η yᵢ + xᵢ",
      "w(k+1) := w(k) η yᵢ xᵢ",
      "w(k+1) := w(k) + η yᵢ + xᵢ"
    ],
    "correct": [
      "w(k+1) := w(k) + η yᵢ xᵢ"
    ]
  },
  {
    "question": "Granica decyzyjna, którą wyznacza perceptron prosty, jest w ogólności:",
    "options": [
      "prostą",
      "sferą",
      "hiperpłaszczyzną",
      "elipsoidą"
    ],
    "correct": [
      "hiperpłaszczyzną"
    ]
  },
  {
    "question": "Dowód twierdzenia Novikoffa pokazuje m.in., że iloczyn skalarny wektora wag i wektora optymalnego (w(k), w*) jest w trakcie algorytmu uczenia ograniczony z dołu przez:",
    "options": [
      "√k * const",
      "k² * const",
      "k * const",
      "żadne z powyższych"
    ],
    "correct": [
      "k * const"
    ]
  },
  {
    "question": "Dowód twierdzenia Novikoffa pokazuje m.in., że norma wektora wag ||w(k)|| jest w trakcie algorytmu uczenia ograniczona z góry przez:",
    "options": [
      "√k * const",
      "k² * const",
      "k * const",
      "żadne z powyższych"
    ],
    "correct": [
      "√k * const"
    ]
  },
  {
    "question": "Sztuczka 'podnoszenia wymiarowości' w połączeniu z perceptronem prostym ma na celu próbę znalezienia rozwiązania (klasyfikatora) dla zbiorów danych:",
    "options": [
      "małej liczby przykładów",
      "dużej liczby przykładów",
      "separowalnych liniowo",
      "nieseparowalnych liniowo"
    ],
    "correct": [
      "nieseparowalnych liniowo"
    ]
  },
  {
    "question": "W perceptronie wielowarstwowym rekurencja 'back-propagation' pozwala obliczyć wartość błędu Ei,j (dla j-tego neuronu w warstwie t) wzorem:",
    "options": [
      "Φt,j(1-Φt,k)Σk vt,k,j Et+1,k",
      "Φt,j(1-Φt,k)Σk vt,k,j Et-1,k",
      "Φt,j(1-Φt,k)Σk vt-1,k,j Et-1,k",
      "Φt,j(1-Φt,k)Σk vt-1,k,j Et+1,k"
    ],
    "correct": [
      "Φt,j(1-Φt,k)Σk vt-1,k,j Et+1,k"
    ]
  },
  {
    "question": "Sigmoidalna funkcja aktywacji w perceptronie wielowarstwowym określona jest wzorem:",
    "options": [
      "Φ(s) = 1 / (1 - exp(s))",
      "Φ(s) = 1 / (1 - exp(-s))",
      "Φ(s) = 1 / (1 + exp(s))",
      "Φ(s) = 1 / (1 + exp(-s))"
    ],
    "correct": [
      "Φ(s) = 1 / (1 + exp(-s))"
    ]
  },
  {
    "question": "Prawdopodobieństwo przejścia osobnika x do następnego pokolenia w selekcji ruletkowej można zapisać wzorem:",
    "options": [
      "ƒ(x) / Σt ƒ(t)",
      "rankƒ(x) / Σt rankƒ(t)",
      "ƒ(x) / max t ƒ(t)",
      "ƒ(x) / min t ƒ(t)"
    ],
    "correct": [
      "ƒ(x) / Σt ƒ(t)"
    ]
  },
  {
    "question": "Dany jest dyskretny problem plecakowy o n przedmiotach i objętości plecaka C. Rozwiązanie poprzez programowanie dynamiczne ma złożoność:",
    "options": [
      "O(C^n)",
      "O(nC)",
      "O(C+n)",
      "O(Cn)"
    ],
    "correct": [
      "O(nC)"
    ]
  },
  {
    "question": "Problem n-hetmanów polega na ustawieniu n hetmanów (bez wzajemnego ataku) na szachownicy o wymiarach:",
    "options": [
      "4×4",
      "8×8",
      "n×n",
      "(n²-1)×(n²-1)"
    ],
    "correct": [
      "n×n"
    ]
  },
  {
    "question": "'Problem jeepa' jest przykładem problemu:",
    "options": [
      "optymalizacji dyskretnej",
      "najkrótszej ścieżki",
      "klasyfikacji binarnej",
      "aproksymacji"
    ],
    "correct": [
      "optymalizacji dyskretnej"
    ]
  },
  {
    "question": "'Problem komiwojażera' to problem:",
    "options": [
      "NP-zupełny",
      "NP-trudny",
      "decyzyjny",
      "klasyfikacji"
    ],
    "correct": [
      "NP-trudny"
    ]
  },
  {
    "question": "W grze w pojedynczy 'dylemat więźnia' racjonalnym wyborem dla każdego z graczy jest:",
    "options": [
      "milczeć",
      "zdradzić",
      "postąpić jak przeciwnik",
      "postąpić odwrotnie niż przeciwnik"
    ],
    "correct": [
      "zdradzić"
    ]
  },
  {
    "question": "Program komputerowy grający w 'grę w naśladownictwo' nie powinien udzielać:",
    "options": [
      "błędnych odpowiedzi",
      "tylko poprawnych odpowiedzi",
      "odpowiedzi po zbyt długim namyśle",
      "odpowiedzi randomizowanych"
    ],
    "correct": [
      "tylko poprawnych odpowiedzi"
    ]
  },
  {
    "question": "Bezpośrednio po wygenerowaniu potomków algorytmy przeszukujące grafy:",
    "options": [
      "sprawdzają obecność potomków w zbiorze Open",
      "sprawdzają obecność potomków w zbiorze Closed",
      "sprawdzają monotoniczność heurystyki",
      "sprawdzają dopuszczalność heurystyki"
    ],
    "correct": [
      "sprawdzają obecność potomków w zbiorze Closed"
    ]
  },
  {
    "question": "Stan pobrany ze zbioru Open w algorytmie Best-first-search jest w stosunku do pozostałych stanów w Open stanem o:",
    "options": [
      "najmniejszej wartości h(s)",
      "największej wartości h(s)",
      "najmniejszej wartości g(s) + h(s)",
      "największej wartości g(s) + h(s)"
    ],
    "correct": [
      "najmniejszej wartości g(s) + h(s)"
    ]
  },
  {
    "question": "W pewnym algorytmie A* zrealizowano zbiór Open na kopcu binarnym typu MIN. Najbardziej wymagającą operacją jest wówczas:",
    "options": [
      "podejrzenie stanu minimalnego",
      "pobranie stanu minimalnego",
      "dodanie stanu",
      "podmiana stanu"
    ],
    "correct": [
      "podmiana stanu"
    ]
  },
  {
    "question": "Sudoku minimalne to sudoku:",
    "options": [
      "najmniejszej liczbie danych i 1 rozwiązaniu",
      "najmniejszej liczbie danych i 2 rozwiązaniach",
      "dla planszy 4×4",
      "dla planszy 1×1"
    ],
    "correct": [
      "najmniejszej liczbie danych i 1 rozwiązaniu"
    ]
  },
  {
    "question": "Dla układanki puzzle przesuwne postaci (cyfry pisane kolejno wierszami): (1,0,5;3,2,4;6,7,8) wartość heurystyki 'Misplaced tiles' wynosi:",
    "options": [
      "2",
      "3",
      "4",
      "5"
    ],
    "correct": [
      "5"
    ]
  },
  {
    "question": "Dla układanki puzzle przesuwne postaci (cyfry pisane kolejno wierszami): (1,8,2;0,4,3;7,6,5) wartość heurystyki 'Manhattan' wynosi:",
    "options": [
      "9",
      "10",
      "7",
      "8"
    ],
    "correct": [
      "9"
    ]
  },
  {
    "question": "Dla układanki puzzle przesuwne postaci (cyfry pisane kolejno wierszami): (1,0,5;3,2,4;6,7,8) wartość heurystyki 'Manhattan' wynosi:",
    "options": [
      "2",
      "3",
      "4",
      "5"
    ],
    "correct": [
      "5"
    ]
  },
  {
    "question": "W pewnym trójwymiarowym labiryncie gracz ma współrzędne (x,y,z) i może wykonywać tylko ruchy (←,→,↑,↓). Miejsce docelowe ma współrzędne (x0,y0,z0). Niech h1(x,y,z)=|x-x0|+|y-y0|+|z-z0| oraz h2(x,y,z)=√((x-x0)²+(y-y0)²+(z-z0)²) oznaczają pewne heurystyki. Prawdziwe jest zdanie:",
    "options": [
      "h1 i h2 nie są dopuszczalne",
      "h1 i h2 są dopuszczalne",
      "h1 jest dopuszczalna, h2 jest niedopuszczalna",
      "h2 jest dopuszczalna, h1 jest niedopuszczalna"
    ],
    "correct": [
      "h1 i h2 są dopuszczalne"
    ]
  },
  {
    "question": "Ścieżkę minimalną prowadzącą do rozwiązania puzzli przesuwnych można znaleźć za pomocą:",
    "options": [
      "algorytmu Breadth-first-search",
      "algorytmu Best-first-search",
      "algorytmu Dijkstry",
      "żadne z powyższych"
    ],
    "correct": [
      "algorytmu Best-first-search"
    ]
  },
  {
    "question": "Niech b oznacza stały współczynnik rozgałęziania pewnej gry, a D liczbę poziomów drzewa, które chcemy zbadać (D parzyste). Dokładną liczbę stanów odwiedzonych przez algorytm MIN-MAX przedstawia wyrażenie:",
    "options": [
      "b^D",
      "b^(D/2)",
      "b^(D+1) - 1",
      "(b^(D+1) - 1) / (b - 1)"
    ],
    "correct": [
      "(b^(D+1) - 1) / (b - 1)"
    ]
  },
  {
    "question": "W przycinaniu α-β analizowany jest pewien stan typu MIN, dla którego procedurę wywołano z początkowymi wartościami α=10, β=15. Przypuśćmy, że wartości zwracane do tego stanu ze stanów potomnych będą wynosiły kolejno 13, -∞, 17, 4, ∞. Przycięcie nastąpi po:",
    "options": [
      "pierwszym potomku",
      "drugim potomku",
      "trzecim potomku",
      "czwartym potomku"
    ],
    "correct": [
      "drugim potomku"
    ]
  },
  {
    "question": "W przycinaniu α-β analizowany jest pewien stan typu MAX, dla którego procedurę wywołano z początkowymi wartościami α=10, β=15. Przypuśćmy, że wartości zwracane do tego stanu ze stanów potomnych będą wynosiły kolejno 13, -∞, 17, 4, ∞. Wtedy:",
    "options": [
      "przycięcie nie nastąpi wcale",
      "przycięcie nastąpi po tym samym potomku, co w stanie typu MIN z takimi samymi początkowymi i zwracanymi wartościami",
      "przycięcie nastąpi po innym potomku, co w stanie typu MIN z takimi samymi początkowymi i zwracanymi wartościami",
      "stan typu MAX nie może przybrać takich wartości"
    ],
    "correct": [
      "przycięcie nastąpi po innym potomku, co w stanie typu MIN z takimi samymi początkowymi i zwracanymi wartościami"
    ]
  },
  {
    "question": "W perceptronie prostym aktualny wektor wag wynosi (3, 1, -2, 2). Do poprawki wybrano przykład xi = (1, 2, 1, 2). Wynika z tego, że:",
    "options": [
      "yi = -1",
      "yi = 1",
      "nie można wywnioskować klasy",
      "algorytm nie zatrzyma się"
    ],
    "correct": [
      "yi = -1"
    ]
  },
  {
    "question": "W perceptronie prostym aktualny wektor wag wynosi (3, 1, -2, 2). Do poprawki wybrano przykład xi = (1, 2, 1, 2). Współczynnik uczenia wynosi 0.5. Wynika z tego, że nowy wektor wag będzie równy:",
    "options": [
      "(-2.5, 0, 2.5, -1)",
      "(2.5, 0, -2.5, 1)",
      "(-3.5, -2, 1.5, -3)",
      "(1.5, 2, -1.5, 3)"
    ],
    "correct": [
      "(-3.5, -2, 1.5, -3)"
    ]
  },
  {
    "question": "Zgodnie z dowodem twierdzenia Novikoffa, jeżeli zbiór danych jest liniowo separowalny, to algorytm perceptronu wykona nie więcej kroków niż:",
    "options": [
      "γ_min² / R_max",
      "R_max / γ_min²",
      "γ_min² / R_max²",
      "R_max² / γ_min²"
    ],
    "correct": [
      "R_max² / γ_min²"
    ]
  },
  {
    "question": "Pewien zbiór danych określony na płaszczyźnie (w R²) nie jest liniowo separowalny. Dokonano pewnego przekształcenia współrzędnych tego zbioru redukując go do zbioru jednowymiarowego (określonego w R¹). Można powiedzieć, że:",
    "options": [
      "nowy zbiór również nie jest liniowo-separowalny",
      "nowy zbiór może być liniowo-separowalny",
      "wspomniane przekształcenie nie jest możliwe",
      "żadne z powyższych"
    ],
    "correct": [
      "nowy zbiór również nie jest liniowo-separowalny"
    ]
  },
  {
    "question": "Jeżeli dla sieci MLP używana jest sigmoidalna funkcja aktywacji Φ(s), to zachodzi związek:",
    "options": [
      "Φ(s) = Φ'(s) (1 - Φ'(s))",
      "Φ(s) = -Φ'(s) (1 + Φ'(s))",
      "Φ'(s) = Φ(s) (1 - Φ(s))",
      "Φ'(s) = -Φ(s) (1 + Φ(s))"
    ],
    "correct": [
      "Φ'(s) = Φ(s) (1 - Φ(s))"
    ]
  },
  {
    "question": "Uczenie sieci MLP w wariancie on-line oznacza, że poprawki wag:",
    "options": [
      "następują po obejrzeniu każdego przykładu",
      "następują po obejrzeniu wszystkich przykładów",
      "następują warstwa po warstwie idąc wstecz",
      "następują warstwa po warstwie idąc w przód"
    ],
    "correct": [
      "następują po obejrzeniu każdego przykładu"
    ]
  },
  {
    "question": "W selekcji ruletkowej wartość oczekiwaną liczby egzemplarzy pewnego osobnika x₁ po selekcji można wyrazić wzorem:",
    "options": [
      "(ƒ(xᵢ)) / (Σᵐⱼ=₁ƒ(xⱼ))",
      "(ƒ(xᵢ)) / (1/m Σᵐⱼ=₁ƒ(xⱼ))",
      "(Σᵐⱼ=₁ƒ(xⱼ)) / (ƒ(xᵢ))",
      "(1/m Σᵐⱼ=₁ƒ(xⱼ)) / (ƒ(xᵢ))"
    ],
    "correct": [
      "(ƒ(xᵢ)) / (1/m Σᵐⱼ=₁ƒ(xⱼ))"
    ]
  },
  {
    "question": "Algorytm Breadth-first search nie może odwiedzić stanu o głębokości d, jeżeli zbiór Open:",
    "options": [
      "zawiera stany o głębokości d-1",
      "zawiera stany o głębokości d+1",
      "jest pusty",
      "jest pełny"
    ],
    "correct": [
      "zawiera stany o głębokości d-1"
    ]
  },
  {
    "question": "Prawdziwe jest następujące zdanie o związku pomiędzy algorytmami A*, Best-first search (BFS) i Dijkstry:",
    "options": [
      "A* i BFS są szczególnymi przypadkami algorytmu Dijkstry",
      "A* jest szczególnym przypadkiem BFS",
      "A* i algorytm Dijkstry są szczególnymi przypadkami BFS",
      "BFS i algorytm Dijkstry są szczególnymi przypadkami A*"
    ],
    "correct": [
      "BFS i algorytm Dijkstry są szczególnymi przypadkami A*"
    ]
  },
  {
    "question": "Algorytm A* używa funkcji heurystycznej h, aby:",
    "options": [
      "mierzyć odległość przebytą dotychczas",
      "oszacować odległość pozostałą do celu",
      "oszacować sumę odległości",
      "odrzucić już odwiedzone stany"
    ],
    "correct": [
      "oszacować odległość pozostałą do celu"
    ]
  },
  {
    "question": "Jeżeli t jest stanem-potomkiem stanu s(rodzic) w przeszukiwaniu za pomocą A* z heurystyką monotoniczną, wtedy:",
    "options": [
      "g(t) ≤ g(s) + h(s)",
      "ƒ(t) ≥ ƒ(s)",
      "g(t) ≥ g(s) + h(s)",
      "ƒ(t) ≤ ƒ(s)"
    ],
    "correct": [
      "ƒ(t) ≥ ƒ(s)"
    ]
  },
  {
    "question": "Jeżeli zbiór Open jest zaimplementowany jako standardowa kolejka FIFO, wtedy czas pobrania (i usunięcia) elementu minimalnego jest:",
    "options": [
      "logarytmiczny",
      "stały",
      "liniowy",
      "żadne z powyższych"
    ],
    "correct": [
      "liniowy"
    ]
  },
  {
    "question": "Jeżeli zbiór Open jest zaimplementowany jako kolejka priorytetowa (na kopcu binarnym) i zawiera n elementów, wówczas pobranie (i usunięcie) elementu minimalnego wymaga czasu:",
    "options": [
      "O(n)",
      "O(1)",
      "O(log₂n)",
      "O(n log₂n)"
    ],
    "correct": [
      "O(log₂n)"
    ]
  },
  {
    "question": "Jeżeli zbiór Open jest zaimplementowany jako kolejka priorytetowa (na kopcu binarnym) i zawiera n elementów, wówczas włożenie nowego elementu wymaga czasu:",
    "options": [
      "O(n)",
      "O(1)",
      "O(log₂n)",
      "O(n log₂n)"
    ],
    "correct": [
      "O(log₂n)"
    ]
  },
  {
    "question": "W algorytmie A* o zbiorze Closed można powiedzieć, że:",
    "options": [
      "nie może być większego rozmiaru niż zbiór Open",
      "stanowi wystarczający warunek stopu algorytmu",
      "pozwala sprawdzić, czy pewien stan był już odwiedzony",
      "można go zignorować, jeżeli graf zawiera cykl"
    ],
    "correct": [
      "pozwala sprawdzić, czy pewien stan był już odwiedzony"
    ]
  },
  {
    "question": "Prawdziwe jest następujące zdanie na temat kosztów operacji (put, get) na zbiorze Closed implementowanym jako mapa haszująca:",
    "options": [
      "koszty zamortyzowane są O(log₂n)",
      "koszty w najgorszym wypadku są O(log₂n)",
      "koszty zamortyzowane są O(1)",
      "koszty w najgorszym wypadku są O(1)"
    ],
    "correct": [
      "koszty zamortyzowane są O(1)"
    ]
  },
  {
    "question": "W ramach zadanej głębokości algorytm MIN-MAX może być postrzegany jako:",
    "options": [
      "algorytm zachłanny",
      "algorytm sortujący",
      "algorytm wyczerpujący",
      "żadne z powyższych"
    ],
    "correct": [
      "algorytm wyczerpujący"
    ]
  },
  {
    "question": "Algorytm 'przycinanie α−β' wywoła rekurencję (w dół) na rzecz pewnego stanu, jeżeli:",
    "options": [
      "α > β",
      "α ≥ β",
      "α < β",
      "α ≤ β"
    ],
    "correct": [
      "α < β"
    ]
  },
  {
    "question": "Prawdziwe jest następujące zdanie o algorytmie 'przycinanie α−β':",
    "options": [
      "gwarantuje odwiedzenie mniejszej liczby stanów niż MIN-MAX",
      "aproksymuje odpowiedź algorytmu MIN-MAX",
      "gwarantuje zasugerowanie takich samych najlepszych ruchów jak MIN-MAX",
      "żadne z powyższych"
    ],
    "correct": [
      "gwarantuje zasugerowanie takich samych najlepszych ruchów jak MIN-MAX"
    ]
  },
  {
    "question": "Jeżeli D to maksymalna głębokość, a b współczynnik rozgałęzienia, to złożoność 'przycinania α−β' pruning jest proporcjonalna do:",
    "options": [
      "bD w przypadku pesymistycznym",
      "√(bD) w przypadku pesymistycznym",
      "bD w przypadku pesymistycznym",
      "√(bD) w przypadku optymistycznym"
    ],
    "correct": [
      "bD w przypadku pesymistycznym"
    ]
  },
  {
    "question": "Perceptron prosty (inaczej perceptron Rosenblatta) próbuje rozwiązać zadanie:",
    "options": [
      "klasyfikacji binarnej",
      "optymalizacji dyskretnej",
      "optymalizacji ciągłej",
      "optymalizacji mieszanej"
    ],
    "correct": [
      "klasyfikacji binarnej"
    ]
  },
  {
    "question": "Załóżmy, że w perceptronie prostym wektor wag w = {2, 3, -1, -1} ma zostać skorygowany na przykładzie x = {1, 0, 2, -1}, y=-1, przy v=0.5. Prawdziwe jest zdanie:",
    "options": [
      "nowy wektor to ω = (2.5, 3, 0, -1.5)",
      "nowy wektor to ω = (1.5, 3, -2, -0.5)",
      "poprawka jest niepotrzebna, bo przykład jest dobrze sklasyfikowany",
      "podane w pytaniu informacje są niewystarczające do określenia nowego wektora"
    ],
    "correct": [
      "nowy wektor to ω = (1.5, 3, -2, -0.5)"
    ]
  },
  {
    "question": "Twierdzenie Novikoffa implikuje, że algorytm uczący (perceptron prosty) zatrzyma się po skończonej liczbie kroków:",
    "options": [
      "zawsze",
      "jeżeli zbiór danych jest liniowo-separowalny",
      "jeżeli zbiór danych nie jest liniowo-separowalny",
      "gdy dane podniesiemy do wyższej wymiarowości"
    ],
    "correct": [
      "jeżeli zbiór danych jest liniowo-separowalny"
    ]
  },
  {
    "question": "Górne ograniczenie na liczbę kroków podane przez Novikoffa jest:",
    "options": [
      "proporcjonalne do kwadratu promienia danych k ≤ R² / y'²",
      "proporcjonalne do promienia danych",
      "odwrotnie proporcjonalne do kwadratu promienia danych",
      "odwrotnie proporcjonalne do promienia danych"
    ],
    "correct": [
      "proporcjonalne do kwadratu promienia danych k ≤ R² / y'²"
    ]
  },
  {
    "question": "Niech ω* oznacza nieznany wektor separujący. Jeżeli dane są liniowo separowalne, wtedy podczas algorytmu wyrażenie ω(k), ω*: ",
    "options": [
      "nie maleje",
      "nie rośnie",
      "pozostaje stałe",
      "zależy od wielkości ||ω(k)||"
    ],
    "correct": [
      "nie maleje"
    ]
  },
  {
    "question": "W perceptronie wielowarstwowym (MLP) sigmoidalna funkcja aktywacji ϕ(s) ma postać:",
    "options": [
      "1 / (1 - exp(s))",
      "1 / (1 - exp(-s))",
      "1 / (1 + exp(s))",
      "1 / (1 + exp(-s))"
    ],
    "correct": [
      "1 / (1 + exp(-s))"
    ]
  },
  {
    "question": "Prawdziwy jest następujący związek pomiędzy ϕ(s) i jej pochodną:",
    "options": [
      "ϕ(s) = ϕ’(s)(1 - ϕ’(s))",
      "ϕ(s) = ϕ’(s)(1 + ϕ(s))",
      "ϕ’(s) = ϕ(s)(1 + ϕ(s))",
      "ϕ’(s) = ϕ(s)(1 - ϕ(s))"
    ],
    "correct": [
      "ϕ’(s) = ϕ(s)(1 - ϕ(s))"
    ]
  },
  {
    "question": "Która z poniższych selekcji najdłużej utrzymuje różnorodność populacji (statystycznie)?:",
    "options": [
      "ruletkowa",
      "rankingowa",
      "deterministyczna",
      "nie można rozstrzygnąć"
    ],
    "correct": [
      "rankingowa"
    ]
  },
  {
    "question": "Algorytm Depth-first search nie może odwiedzić stanu o głębokości d, gdy Open zawiera stany o głębokości:",
    "options": [
      "d-1",
      "d+1",
      "d",
      "żadne z powyższych"
    ],
    "correct": [
      "d+1"
    ]
  },
  {
    "question": "Prawdziwe jest następujące zdanie na temat związku pomiędzy algorytmami A* i Dijkstry dla ustalonego problemu:",
    "options": [
      "A* wykona nie więcej iteracji niż algorytm Dijkstry",
      "A* wykona nie mniej iteracji niż algorytm Dijkstry",
      "A* wykona tyle samo iteracji co algorytm Dijkstry",
      "nie wiadomo"
    ],
    "correct": [
      "A* wykona nie więcej iteracji niż algorytm Dijkstry"
    ]
  },
  {
    "question": "W algorytmie Best-first search porządek odwiedzania stanów jest określony wg:",
    "options": [
      "kosztu przebytego dotychczas",
      "szacowanego kosztu pozostałego do celu",
      "głębokości",
      "żadne z powyższych"
    ],
    "correct": [
      "szacowanego kosztu pozostałego do celu"
    ]
  },
  {
    "question": "Jako konwencję dla funkcji heurystycznych h, przyjmuje się że:",
    "options": [
      "h(s) < 0 dla wszystkich s",
      "h(s) ≤ 0 dla wszystkich s",
      "h(s) > 0 dla wszystkich s",
      "h(s) ≥ 0 dla wszystkich s"
    ],
    "correct": [
      "h(s) ≥ 0 dla wszystkich s"
    ]
  },
  {
    "question": "Jeżeli szukamy najkrótszej ścieżki w grafie geograficznym za pomocą A*, to odległość:",
    "options": [
      "euklidesowa może być niedopuszczalną heurystyką",
      "euklidesowa jest zawsze dopuszczalną heurystyką",
      "Manhattan jest zawsze dopuszczalną heurystyką",
      "Manhattan nie doszacowuje odległości euklidesową"
    ],
    "correct": [
      "euklidesowa jest zawsze dopuszczalną heurystyką"
    ]
  },
  {
    "question": "Jeżeli stan t jest pewnym potomkiem stanu s, to warunek monotoniczności heurystyki można zapisać jako:",
    "options": [
      "s,t h(t) ≥ h(s) - g(t) - g(s)",
      "s,t h(t) ≥ h(s) - g(t) + g(s)",
      "s,t h(s) ≥ h(t) - g(t) - g(s)",
      "s,t h(s) ≥ h(t) - g(t) + g(s)"
    ],
    "correct": [
      "s,t h(t) ≥ h(s) - g(t) + g(s)"
    ]
  },
  {
    "question": "Warunek monotoniczności heurystyki można także wypowiedzieć jako:",
    "options": [
      "s, t h(t) ≤ g(s) − g(t) + h(s)",
      "s, t f(s) ≤ g(t) − g(s) + h(s)",
      "s, t h(s) ≤ g(t) − g(s) + h(s)",
      "s, t h(s) ≤ g(t) − g(s) + h(t)"
    ],
    "correct": [
      "s, t h(s) ≤ g(t) − g(s) + h(t)"
    ]
  },
  {
    "question": "Jeżeli zbiór Open jest kolejką priorytetową (na kopcu binarnym) i zawiera n elementów, to pobranie (i usunięcie) elementu minimalnego wymaga czasu:",
    "options": [
      "O(n)",
      "O(1)",
      "O(log₂n)",
      "O(n log₂n)"
    ],
    "correct": [
      "O(log₂n)"
    ]
  },
  {
    "question": "Prawdziwe jest następujące zdanie na temat zbioru Closed w algorytmie A*:",
    "options": [
      "może być pominięty, jeżeli graf nie ma cykli",
      "nie może przewyższać rozmiarem zbioru Open",
      "stanowi wystarczający warunek stopu algorytmu",
      "nie pozwala sprawdzać, czy stan był już odwiedzony"
    ],
    "correct": [
      "może być pominięty, jeżeli graf nie ma cykli"
    ]
  },
  {
    "question": "Prawdziwe jest następujące zdanie na temat kosztów operacji (put, get) w zbiorze Closed będącym mapą haszującą:",
    "options": [
      "zamortyzowane koszty są O(1)",
      "koszty w najgorszym przypadku są O(1)",
      "zamortyzowane koszty są O(log₂n)",
      "koszty w najgorszym przypadku są O(log₂n)"
    ],
    "correct": [
      "zamortyzowane koszty są O(1)"
    ]
  },
  {
    "question": "W układance puzzle przesuwne niech hMT, hM, hM+LC oznaczają odpowiednio heurystyki: Misplaced Tiles, Manhattan oraz Manhattan + Linear Conflicts. Prawdziwe jest zdanie:",
    "options": [
      "hMT zaniedbuje odległości płytek od ich miejsc docelowych",
      "hM nie jest monotoniczna",
      "hMT+LC(s) dodaje 1 za każdy konflikt liniowy",
      "hMT(s) ≥ hM(s) dla wszystkich stanów s"
    ],
    "correct": [
      "hMT zaniedbuje odległości płytek od ich miejsc docelowych"
    ]
  },
  {
    "question": "W przeszukiwaniu drzewa gry, gdy b jest współczynnikiem rozgałęziania i rozważa się przynajmniej 2 półruchy, to złożoność w najgorszym przypadku skaluje się:",
    "options": [
      "liniowo z b",
      "wykładniczo z b",
      "wielomianowo z b",
      "logarytmicznie z b"
    ],
    "correct": [
      "wykładniczo z b"
    ]
  },
  {
    "question": "Dla głębokości maksymalnej D i współczynnika rozgałęziania b złożoność algorytmu MIN-MAX jest:",
    "options": [
      "O(dB)",
      "O(D+b)",
      "O(Db)",
      "O(b^D)"
    ],
    "correct": [
      "O(b^D)"
    ]
  },
  {
    "question": "'Przycinanie α−β' odwiedza potomka aktualnego stanu, kiedy:",
    "options": [
      "α > β",
      "α ≥ β",
      "α < β",
      "α ≤ β"
    ],
    "correct": [
      "α < β"
    ]
  },
  {
    "question": "Prawdziwe jest następujące zdanie dla przycinania α−β (b współczynnik rozgałęziania, D maksymalna głębokość):",
    "options": [
      "ma taką samą pesymistyczną złożoność jak MIN-MAX",
      "ma taką samą optymistyczną złożoność jak MIN-MAX",
      "ma wykładniczą złożoność ze względu na b",
      "ma wielomianową złożoność ze względu na D"
    ],
    "correct": [
      "ma taką samą pesymistyczną złożoność jak MIN-MAX"
    ]
  },
  {
    "question": "Perceptron prosty (lub perceptron Rosenblatta) poszukuje:",
    "options": [
      "wielomianowej granicy decyzyjnej",
      "liniowej granicy decyzyjnej",
      "maksimum iloczynu skalarnego",
      "minimum iloczynu skalarnego"
    ],
    "correct": [
      "liniowej granicy decyzyjnej"
    ]
  },
  {
    "question": "Perceptron prosty poprawia wagi wg wzoru:",
    "options": [
      "ω(k+1) := ηxᵢyᵢ",
      "ω(k+1) := −ηxᵢyᵢ",
      "ω(k+1) := ω(k) − ηxᵢyᵢ",
      "ω(k+1) := ω(k) + ηxᵢyᵢ"
    ],
    "correct": [
      "ω(k+1) := ω(k) + ηxᵢyᵢ"
    ]
  },
  {
    "question": "W perceptronie prostym wektor wag ω=(0, 3, −1, −1) jest testowany dla przykładu x=(1, 0, 2, −1), y=1. Można powiedzieć, że:",
    "options": [
      "przykład jest poprawnie sklasyfikowany",
      "przykład jest błędnie sklasyfikowany",
      "nie można wykonać testu, ponieważ ω₀=0",
      "żadne z powyższych"
    ],
    "correct": [
      "przykład jest błędnie sklasyfikowany"
    ]
  },
  {
    "question": "Zgodnie z dowodem twierdzenia Novikoffa, warunki ściskające na iloczyn skalarny ω(k), ω* mają postać:",
    "options": [
      "kγ'min ≥ ω(k), ω* ≥ √kRmax",
      "kγ'²min ≥ ω(k), ω* ≥ √kR²max",
      "kγ'min ≤ ω(k), ω* ≥ √kRmax",
      "kγ'²min ≤ ω(k), ω* ≥ √kR²max"
    ],
    "correct": [
      "kγ'min ≤ ω(k), ω* ≥ √kRmax"
    ]
  },
  {
    "question": "Jeżeli algorytm uczący perceptron Rosenblatta wpada w nieskończoną pętlę, to oznacza, że:",
    "options": [
      "dane nie są liniowo separowalne",
      "dane są liniowo separowalne",
      "twierdzenie Novikoffa nie obejmuje tego przypadku",
      "żadne z powyższych"
    ],
    "correct": [
      "dane nie są liniowo separowalne"
    ]
  },
  {
    "question": "Przypuśćmy, że zaprojektowano wariant perceptronu prostego bez wyrazu wolnego, tj. ω₀=0 (zawsze). Wtedy:",
    "options": [
      "algorytm jest niestabilny",
      "algorytm nie zatrzyma się",
      "algorytm i tak się zatrzyma",
      "niektóre zbiory danych nie pozwolą się sklasyfikować"
    ],
    "correct": [
      "niektóre zbiory danych nie pozwolą się sklasyfikować"
    ]
  },
  {
    "question": "W perceptronie wielowarstwowym (MLP) sigmoidalna funkcja aktywacji ϕ(s) jest:",
    "options": [
      "monotoniczna",
      "niemonotoniczna",
      "parzysta",
      "jednomodalna"
    ],
    "correct": [
      "monotoniczna"
    ]
  },
  {
    "question": "Pochodną funkcji ϕ(s) można zapisać jako:",
    "options": [
      "ϕ′(s) = exp(-s) / (1 + exp(-s))",
      "ϕ′(s) = -exp(-s) / (1 + exp(-s))",
      "ϕ′(s) = exp(-s) / (1 + exp(-s))²",
      "ϕ′(s) = -exp(-s) / (1 + exp(-s))²"
    ],
    "correct": [
      "ϕ′(s) = exp(-s) / (1 + exp(-s))²"
    ]
  },
  {
    "question": "Niech x* oznacza osobnika z najlepszym przystosowaniem w aktualnej populacji. Wtedy:",
    "options": [
      "tylko selekcja rankingowa gwarantuje jego sukcesję",
      "tylko selekcja ruletkowa gwarantuje jego sukcesję",
      "obie selekcje ruletkowa i rankingowa gwarantują jego sukcesję",
      "żadne z powyższych"
    ],
    "correct": [
      "żadne z powyższych"
    ]
  },
  {
    "question": "Programowanie dynamiczne dla dyskretnego problemu plecakowego (DKP) o n elementach wymaga wykładniczego czasu, gdy objętość plecaka C jest proporcjonalna do:",
    "options": [
      "n",
      "2ⁿ",
      "n²",
      "1"
    ],
    "correct": [
      "2ⁿ"
    ]
  },
  {
    "question": "Kluczowe przejście indukcyjne w programowaniu dynamicznym dla dyskretnego problemu plecakowego ma postać:",
    "options": [
      "aᵢⱼ = max{aᵢⱼ₋₁, aᵢ₋cⱼ,ⱼ₋₁ + vⱼ}",
      "aᵢⱼ = max{aᵢⱼ₋₁, aᵢⱼ₋₁ − Cⱼ + vⱼ}",
      "aᵢⱼ = max{aᵢⱼ₋₁, aᵢ₋₁,ⱼ₋₁ + vⱼ}",
      "aᵢⱼ = max{aᵢⱼ₋₁, aᵢ₋₁,ⱼ₋₁ − Cⱼ + vⱼ}"
    ],
    "correct": [
      "aᵢⱼ = max{aᵢⱼ₋₁, aᵢ₋cⱼ,ⱼ₋₁ + vⱼ}"
    ]
  },
  {
    "question": "W układance puzzle przesuwne niech hMT, hM, hM+LC oznaczają odpowiednio heurystyki: Misplaced Tiles, Manhattan oraz Manhattan + Linear Conflicts. Prawdziwe jest zdanie:",
    "options": [
      "hMT jest dopuszczalna, a hM nie jest",
      "hM jest dopuszczalna, a hMT nie jest",
      "hMT(s) ≥ hM(s) dla wszystkich stanów s",
      "hM+LC(s) ≥ hM(s) dla wszystkich stanów s"
    ],
    "correct": [
      "hM+LC(s) ≥ hM(s) dla wszystkich stanów s"
    ]
  },
  {
    "question": "W pewnym algorytmie genetycznym (maksymalizującym) mamy 4 osobników o przystosowaniach f1 =5, f2=0, f3=10, f4=1. Prawdopodobieństwo sukcesu tych osobników wyniosą: W selekcji rankingowej: 3/10, 1/10, 4/10, 2/10 W selekcji ruletkowej: 5/16, 0, 10/16, 1/16",
    "options": [
      "Prawda",
      "Fałsz"
    ],
    "correct": [
      "Prawda"
    ]
  },
  {
    "question": "W pewnym algorytmie genetycznym (maksymalizującym) mamy 4 osobników o przystosowaniach f1 =5, f2=0, f3=10, f4=1. Prawdopodobieństwo sukcesu tych osobników wyniosą: W selekcji rankingowej: 3/10, 1/10, 4/10, 2/10 W selekcji ruletkowej: 5/16, 0, 10/16, 1/16",
    "options": [
      "Prawda",
      "Fałsz"
    ],
    "correct": [
      "Prawda"
    ]
  },
  {
    "question": "Algorytmy genetyczne służą do rozwiązywania zadań:",
    "options": [
      "aproksymacji",
      "optymalizacji",
      "klasyfikacji binarnej",
      "klasyfikacji"
    ],
    "correct": [
      "optymalizacji"
    ]
  },
  {
    "question": "Algorytmy genetyczne nie wymagają:",
    "options": [
      "generowania liczb losowych",
      "informacji o wartości funkcji optymalizowanej w punkcie",
      "informacji o pochodnej funkcji optymalizowanej w punkcie",
      "selekcji rozwiązań – kandydatów"
    ],
    "correct": [
      "informacji o pochodnej funkcji optymalizowanej w punkcie"
    ]
  },
  {
    "question": "Uczenie sieci neuronowej w trybie on-line oznacza, że: Poprawki następują od razu po obejrzeniu pojedynczego przykładu",
    "options": [
      "Prawda",
      "Fałsz"
    ],
    "correct": [
      "Prawda"
    ]
  },
  {
    "question": "W pewnym algorytmie genetycznym mamy czterech osobników o przystosowaniach f(x1 ) = 2, f(x2 ) = 1, f(x3 ) = 4, f(x4 ) = 9 . Odpowiadające im prawdopodobieństwa sukcesji w selekcji ruletkowej to:",
    "options": [
      "2/9, 1/9, 4/9, 9/9",
      "2/16, 1/16, 4/16, 9/16",
      "0,0,0,1",
      "2/10, 1/10, 3/10, 4/10"
    ],
    "correct": [
      "2/16, 1/16, 4/16, 9/16"
    ]
  },
  {
    "question": "W ramach poprzedniego zadania oczekiwana liczba kopii osobnika x1 po selekcji wynosi?",
    "options": [
      "1",
      "2",
      "12",
      "½"
    ],
    "correct": [
      "½"
    ]
  },
  {
    "question": "W pewnym algorytmie genetycznym mamy 4 osobników o następujących przystosowaniach f(x1 ) = 2, f(x2 ) = 1, f(x3 ) = 4, f(x4 ) = 3. Odpowiadające im prawdopodobieństwa sukcesji dla selekcji rankingowej wynoszą:",
    "options": [
      "2/16, 1/16, 4/16, 3/16",
      "2/4, 1/4, 4/4, 3/4",
      "0, 0, 0, 1",
      "2/10, 1/10, 4/10, 3/10"
    ],
    "correct": [
      "2/10, 1/10, 4/10, 3/10"
    ]
  },
  {
    "question": "Dla warunków z poprzedniego zadania, oczekiwana liczba kopii x1 po selekcji wynosi:",
    "options": [
      "4/10",
      "1/4",
      "4/5 - suma oczekiwanych liczb kopii dla wszystkich osobników powinna być równa liczbie osobników",
      "4* 2/10"
    ],
    "correct": [
      "4/5 - suma oczekiwanych liczb kopii dla wszystkich osobników powinna być równa liczbie osobników"
    ]
  },
  {
    "question": "O sigmoidalnej funkcji aktywacji można powiedzieć, że: jest wszędzie różniczkowalna, jest ściśle rosnąca",
    "options": [
      "Prawda",
      "Fałsz"
    ],
    "correct": [
      "Prawda"
    ]
  },
  {
    "question": "W pewnym AG ma zostać skrzyżowana następująca para rodziców (0,0,1,0,1,1,0,1) i (1,1,1,1,1,0,0,1). Wylosowano punkt krzyżowania jako punkt pomiędzy trzecim i czwartym bitem. W rezultacie otrzymamy:",
    "options": [
      "jednego potomka (0,0,1,1,1,0,0,1)",
      "jednego potomka (1,1,1,0,1,1,0,1)",
      "dwóch potomków (0,0,1,1,1,0,0,1) i (1,1,1,0,1,1,0,1)",
      "ci rodzice nie mogą zostać skrzyżowani"
    ],
    "correct": [
      "dwóch potomków (0,0,1,1,1,0,0,1) i (1,1,1,0,1,1,0,1)"
    ]
  },
  {
    "question": "W perceptronie prostym do poprawki wag w danym kroku mogą być wybrane jedynie przykłady źle sklasyfikowane",
    "options": [
      "Prawda",
      "Fałsz"
    ],
    "correct": [
      "Prawda"
    ]
  },
  {
    "question": "W perceptronie prostym wektor wag w = (1, 2, 3, 4) ma być poprawiony na podstawie pary uczącej x = (1, 0, 1, -1), y = 1 przy współczynniku uczenia eta = 1.0. Prawdziwe jest następujące stwierdzenie: powstanie wektor wynikowy w = (2, 2, 4, 3)",
    "options": [
      "Prawda",
      "Fałsz"
    ],
    "correct": [
      "Prawda"
    ]
  },
  {
    "question": "Jeżeli zbiór danych nie jest liniowo-separowalny, to algorytm uczenia perceptronu prostego nie zatrzyma się",
    "options": [
      "Prawda",
      "Fałsz"
    ],
    "correct": [
      "Prawda"
    ]
  },
  {
    "question": "Uczenie sieci neuronowej w trybie off-line oznacza, że poprawki następują dopiero po obejrzeniu wszystkich przykładów",
    "options": [
      "Prawda",
      "Fałsz"
    ],
    "correct": [
      "Prawda"
    ]
  },
  {
    "question": "W selekcji turniejowej z turniejem o rozmiarze równym rozmiarowi populacji, nowa populacja:",
    "options": [
      "napełnia się najlepszym osobnikiem",
      "losuje najlepszych",
      "zawsze wybiera nowych osobników",
      "tworzy nowe osobniki"
    ],
    "correct": [
      "napełnia się najlepszym osobnikiem"
    ]
  },
  {
    "question": "Algorytmy genetyczne (AG) próbują poszukiwać:",
    "options": [
      "miejsc zerowych",
      "optymów lokalnych",
      "rozwiązań stabilnych",
      "żadne z powyższych"
    ],
    "correct": [
      "żadne z powyższych"
    ]
  },
  {
    "question": "Przykładowym zastosowaniem perceptronu prostego może być:",
    "options": [
      "Kompresja stratna zdjęć",
      "Wyznaczanie najkrótszej ścieżki",
      "Kreślenie linii w grafice 2D",
      "Filtr antyspamowy"
    ],
    "correct": [
      "Filtr antyspamowy"
    ]
  },
  {
    "question": "W „przycinaniu alfa-beta” analizowany jest pewien stan typu MAX, dla którego procedurę wywołano z początkowymi wartościami alfa=10, beta=11. Przypuśćmy, że wartości zwracane dla tego stanu ze stanów potomnych będą wynosiły kolejno: 5,10,11,12,13. Można powiedzieć, że:",
    "options": [
      "Sytuacja ta jest niemożliwa ze względu na wartość pierwszego potomka 5 < alfa",
      "Przycięcie nastąpi po pierwszym potomku",
      "Po drugim potomku",
      "Po trzecim potomku"
    ],
    "correct": [
      "Po trzecim potomku"
    ]
  },
  {
    "question": "Algorytm „przycinanie alfa-beta” uruchomiono dla gry „kółko i krzyżyk”, generując stany potomne aż do maksymalnej możliwej głębokości i oceniając terminale jedną z trzech możliwych wartości: -inf, 0, inf. Można powiedzieć, że:",
    "options": [
      "Algorytm wykryje optymalną sekwencję ruchów, ale przycięcia nie wystąpią",
      "Algorytm wykryje optymalną sekwencję ruchów i przycięcia wystąpią",
      "Algorytm nie wykryje optymalnej sekwencji ruchów i przycięcia nie wystąpią",
      "Algorytm nie wykryje optymalnej sekwencji ruchów, ale przycięcia wystąpią"
    ],
    "correct": [
      "Algorytm wykryje optymalną sekwencję ruchów i przycięcia wystąpią"
    ]
  },
  {
    "question": "Suma ważona obliczana w perceptronie prostym to inaczej:",
    "options": [
      "Iloczyn skalarny wektora danych i wektora wag",
      "Iloczyn wektorowy wektora danych i wektora wag",
      "Norma wektora danych",
      "Norma wektora wag"
    ],
    "correct": [
      "Iloczyn skalarny wektora danych i wektora wag"
    ]
  },
  {
    "question": "Funkcję aktywacji w perceptronie prostym można określić jako funkcję:",
    "options": [
      "Sigmoidalną",
      "Ciągłą",
      "Stałą",
      "Schodkową"
    ],
    "correct": [
      "Schodkową"
    ]
  },
  {
    "question": "Algorytm uczenia dla perceptronu prostego można scharakteryzować jako algorytm:",
    "options": [
      "On-line",
      "Zachłanny",
      "Rekurencyjny",
      "Dziel i zwyciężaj"
    ],
    "correct": [
      "On-line"
    ]
  },
  {
    "question": "Jeżeli zbiór danych jest liniowo-separowalny, to algorytm uczenia perceptronu prostego:",
    "options": [
      "Nie zatrzyma się",
      "Odwiedzi wszystkie przykłady uczące",
      "Odwiedzi tylko podzbiór przykładów uczących",
      "Odpowiednio wyznaczy klasy"
    ],
    "correct": [
      "Odpowiednio wyznaczy klasy"
    ]
  },
  {
    "question": "Jeżeli sieć neuronowa MLP rozwiązuje zadanie estymacji regresji, to o wartościach yi dla przykładów uczących można powiedzieć, że:",
    "options": [
      "Są ze zbioru {-1,1}",
      "Są naturalne",
      "Są rzeczywiste",
      "Są nieznane"
    ],
    "correct": [
      "Są rzeczywiste"
    ]
  },
  {
    "question": "Jeżeli sprawdzenie, czy stan był odwiedzony, ma złożoność O(1), to jest to operacja realizowana:",
    "options": [
      "W miejscu",
      "W czasie stałym",
      "W czasie liniowym",
      "W 1 przebiegu pętli"
    ],
    "correct": [
      "W czasie stałym"
    ]
  },
  {
    "question": "Zbiór Closed realizowany przez mapę haszującą można zastąpić zwykłą tablicą, jeżeli:",
    "options": [
      "Graf nie ma cykli",
      "Graf ma co najwyżej 1 cykl",
      "Liczba węzłów jest znana",
      "Liczba krawędzi jest znana"
    ],
    "correct": [
      "Liczba węzłów jest znana"
    ]
  },
  {
    "question": "Puzzle przesuwane można zaliczyć do grafowych problemów poszukiwania:",
    "options": [
      "Najkrótszej ścieżki",
      "Ścieżki Hamiltona",
      "Ścieżki Eulera",
      "Porządku topologicznego"
    ],
    "correct": [
      "Najkrótszej ścieżki"
    ]
  },
  {
    "question": "W problemie jeepa rozwiązanie dla n=2 wynosi:",
    "options": [
      "1+ ½",
      "1 + 1/3",
      "1 + 1/3 + 1/3",
      "1 + sqrt(2)/2"
    ],
    "correct": [
      "1 + 1/3"
    ]
  },
  {
    "question": "Problem komiwojażera to inaczej problem znalezienia:",
    "options": [
      "Najkrótszego cyklu Hamiltona",
      "Najkrótszego cyklu Eulera",
      "Najkrótszej ścieżki Hamiltona",
      "Najkrótszej ścieżki Eulera"
    ],
    "correct": [
      "Najkrótszego cyklu Hamiltona"
    ]
  },
  {
    "question": "„Iterowany dylemat więźnia” redukuje się indukcyjnie do pojedynczego dylematu więźnia, jeżeli:",
    "options": [
      "Gracze cały czas współpracują",
      "Gracze cały czas zdradzają",
      "Gracze grają wet za wet",
      "Liczba rund jest znana z góry"
    ],
    "correct": [
      "Liczba rund jest znana z góry"
    ]
  },
  {
    "question": "W „grze w życie” Conwaya pusta komórka przeradza się w pełną, jeżeli ma:",
    "options": [
      "Dokładnie 2 sąsiadów",
      "Dokładnie 3 sąsiadów",
      "Dokładnie 2 lub 3 sąsiadów",
      "Żadne z powyższych"
    ],
    "correct": [
      "Dokładnie 3 sąsiadów"
    ]
  },
  {
    "question": "Zdaniem Turinga problem „czy maszyny mogą myśleć?” można rozstrzygnąć tylko przez napisanie programu:",
    "options": [
      "Grającego w naśladownictwo",
      "Grającego w szachy",
      "Komponującego utwory muzyczne",
      "Żadne z powyższych"
    ],
    "correct": [
      "Grającego w naśladownictwo"
    ]
  },
  {
    "question": "Filtr antyspamowy jest przykładem zadania:",
    "options": [
      "Rozpoznawania wzorców",
      "Klasteryzacji binarnej",
      "Przeszukiwania grafu",
      "Indukcji reguł decyzyjnych"
    ],
    "correct": [
      "Rozpoznawania wzorców"
    ]
  },
  {
    "question": "Jako konwencję przyjmuje się, że funkcje heurystyczne w algorytmach grafowych są:",
    "options": [
      "Dodatnie",
      "Nieujemne",
      "Ściśle monotoniczne",
      "Różnowartościowe"
    ],
    "correct": [
      "Nieujemne"
    ]
  },
  {
    "question": "W pewnym binarnym naiwnym klasyfikatorze Bayesa użyto dla bezpieczeństwa numerycznego techniki logarytmowania. Przypuśćmy, że na wejście tego klasyfikatora podstawiono obiekt testowy o cechach (a, b, c)m oraz wiadomo, że\n\nP(X₁ = a | Y = +) = 0.25,  P(X₂ = b | Y = +) = 0.125,  P(X₃ = c | Y = +) = 0.5,  P(Y = +) = 0.5\n\nUżywając logarytmu o podstawie 2, oblicz odpowiedź tego klasyfikatora na rzecz klasy Y = +.\n\nWynosi ona:",
    "options": [
      "(1/2)^6",
      "-6",
      "(1/2)^7",
      "-7"
    ],
    "correct": [
      "-7"
    ]
  },
  {
    "question": "Dla układanki puzzle przesuwne postaci (cyfry pisane kolejno wierszami):\n(7, 0, 8; 6, 5, 4; 3, 1, 2)\nwartość heurystyki 'Manhattan + Linear Conflicts' wynosi",
    "options": [
      "24",
      "37",
      "19",
      "11"
    ],
    "correct": [
      "19"
    ]
  },
  {
    "question": "Dana jest pewna struktura sieci Bayesa. Węzeł A nie ma rodziców i połączony jest z węzłem B, a B wpływa na C. Zakładając, że wszystkie zmienne są binarne, to dla prawidłowego wnioskowania należy podać zestaw następujących prawdopodobieństw:",
    "options": [
      "P(A), P(B), P(C)",
      "P(C|A), P(B|A), P(C|B)",
      "P(A), P(B|A), P(B|egA), P(C|B), P(C|egB)",
      "P(C), P(B|C), P(B|egC), P(A|B), P(A|egB)"
    ],
    "correct": [
      "P(A), P(B|A), P(B|egA), P(C|B), P(C|egB)"
    ]
  },
  {
    "question": "W algorytmie RPROP (przy domyślnych nastawach początkowych)\n\nη₀ = 0.1, α = 1.2, β = 0.5\n\naktualny współczynnik uczenia pewnej konkretnej wagi po czterech aktualizacjach wynosi\n\n0.72η₀\n\nOznacza to, że pochodne funkcji błędu ze względu na tę wagę",
    "options": [
      "nie zmieniały znaku",
      "jednokrotnie zmieniały znak",
      "dwukrotnie zmieniały znak",
      "trzykrotnie zmieniały znak"
    ],
    "correct": [
      "jednokrotnie zmieniały znak"
    ]
  },
  {
    "question": "Schemat wnioskowania sylogizm warunkowy wyraża regułę",
    "options": [
      "Jeżeli prawdziwe jest P i (P ⇒ Q i Q → R), to wnioskujemy prawdziwość R",
      "Jeżeli prawdziwe jest P i (P ⇒ Q i ¬P), to wnioskujemy prawdziwość Q",
      "Jeżeli prawdziwe jest P i (P ⇒ Q i ¬Q), to wnioskujemy prawdziwość P",
      "Jeżeli prawdziwe jest P i (P ⇒ Q i Q), to wnioskujemy prawdziwość Q"
    ],
    "correct": [
      "Jeżeli prawdziwe jest P i (P ⇒ Q i Q → R), to wnioskujemy prawdziwość R"
    ]
  },
  {
    "question": "Dla układanki puzzle przesuwane postaci (cyfry pisane kolejno wierszami):\n(7, 0, 8; 6, 5, 4; 3, 1, 2)\nwartość heurystyki 'Manhattan' wynosi",
    "options": [
      "12",
      "13",
      "11",
      "14"
    ],
    "correct": [
      "13"
    ]
  },
  {
    "question": "Wskaż grupę algorytmów reprezentujących niepoinformowane techniki przeszukiwania grafów",
    "options": [
      "Best-rst search, A*, IDA*",
      "Breadth-rst search, Depth-rst search, algorytm Dijkstry",
      "algorytm Dijkstry, Best-rst search, A*",
      "Breadth-rst search, Depth-rst search, Best-rst search"
    ],
    "correct": [
      "Breadth-rst search, Depth-rst search, algorytm Dijkstry"
    ]
  },
  {
    "question": "W grze w 'iterowany dylemat więźnia'",
    "options": [
      "liczba rund nie powinna być znana graczom z góry",
      "racjonalnym wyborem w każdej rundzie jest: zdradzić",
      "racjonalnym wyborem w każdej rundzie jest: milczeć",
      "najlepszą strategią jest 'wet za wet'"
    ],
    "correct": [
      "liczba rund nie powinna być znana graczom z góry"
    ]
  },
  {
    "question": "Powiedzmy, że pewna sztuczna inteligencja do gry w szachy pracuje z użyciem nastaw: „przycinanie alpha-beta” + głębokość 3.5 + quiescence + tablica transpozycji. Wskaż zmianę, która statystycznie spowoduje największe pogorszenie jakości gry tej sztucznej inteligencji:",
    "options": [
      "Wyłączenie tablicy transpozycji",
      "Obniżenie głębokości do 3.0",
      "Przełączenie algorytmu na „MIN-MAX”",
      "Wyłączenie quiescence"
    ],
    "correct": [
      "Obniżenie głębokości do 3.0"
    ]
  },
  {
    "question": "W 'przycinaniu alfa-beta' analizowany jest pewien stan typu MAX, dla którego procedurę wywołano z początkowymi wartościami\n\nα = 10, β = 15\n\nPrzypuśćmy, że wartości zwracane do tego stanu ze stanów potomnych wynosiłyby kolejno:\n\n13, -∞, 17, 4, ∞\n\nPrzycięcie nastąpi po:",
    "options": [
      "pierwszym potomku",
      "trzecim potomku",
      "czwartym potomku",
      "drugim potomku"
    ],
    "correct": [
      "trzecim potomku"
    ]
  },
  {
    "question": "W logice predykatów pierwszego rzędu podane jest zdanie:\n\n∀x smok(x) ∨ wilkołak(x) ⇒ postaćMagiczna(x)\n\nJaki jest poprawny w Prologu wyrażający tę zależność?",
    "options": [
      "smok(x) :- postaćMagiczna(x), wilkołak(x) :- postaćMagiczna(x).",
      "postaćMagiczna(x) :- smok(x); wilkołak(x).",
      "postaćMagiczna(x) :- smok(x), wilkołak(x).",
      "smok(x); wilkołak(x) :- postaćMagiczna(x)."
    ],
    "correct": [
      "postaćMagiczna(x) :- smok(x); wilkołak(x)."
    ]
  },
  {
    "question": "Co to jest baza wiedzy?",
    "options": [
      "Zbiór zdań w języku formalnym np. w języku opartym na paradygmatach logiki zależny od opisywanej dziedziny/obszaru",
      "Element systemu, który zarządza danymi najczęściej w architekturze klient-serwer",
      "Zbiór danych zapisanych zgodnie z określonymi regułami, np. w postaci tabeli wypełnionej wartościami",
      "Element systemu, który stosuje zasady logiczne by wydedukować nowe informacje"
    ],
    "correct": [
      "Zbiór zdań w języku formalnym np. w języku opartym na paradygmatach logiki zależny od opisywanej dziedziny/obszaru"
    ]
  },
  {
    "question": "Algorytmy genetyczne są przeznaczone",
    "options": [
      "rozwiązywania problemów optymalizacji w sposób przybliżony",
      "rozwiązywania problemów klasykacji w sposób przybliżony",
      "rozwiązywania problemów klasykacji w sposób dokładny",
      "rozwiązywania problemów optymalizacji w sposób dokładny"
    ],
    "correct": [
      "rozwiązywania problemów optymalizacji w sposób przybliżony"
    ]
  },
  {
    "question": "Jeżeli algorytm A* używa jako heurystyki dolnego ograniczenia na odległość do celu, to",
    "options": [
      "nie gwarantuje on znalezienia najkrótszej ścieżki",
      "gwarantuje on znalezienie najkrótszej ścieżki",
      "nie wymaga on zbioru Closed",
      "jest on wolniejszy niż algorytm Dijkstry"
    ],
    "correct": [
      "gwarantuje on znalezienie najkrótszej ścieżki"
    ]
  },
  {
    "question": "Dana jest reguła:\n\nIF zdarzenie A [LS=2.0, LN=0.3] THEN zdarzenie B P(jp)=0.5.\n\nJeżeli podano dowód, zdarzenie A zaistniało, to",
    "options": [
      "poprzez swoją wartość współczynnik LS zmniejszy przekonanie o prawdopodobieństwie zdarzenia B",
      "poprzez swoją wartość współczynnik LN zwiększy przekonanie o prawdopodobieństwie zdarzenia B",
      "prawdopodobieństwo zdarzenia B nie zmieni się.",
      "poprzez swoją wartość współczynnik LS zwiększy przekonanie o prawdopodobieństwie zdarzenia B"
    ],
    "correct": [
      "poprzez swoją wartość współczynnik LS zwiększy przekonanie o prawdopodobieństwie zdarzenia B"
    ]
  },
  {
    "question": "W sieci bayesowskiej węzły reprezentują",
    "options": [
      "wpływ potomków na rodziców",
      "zmienne losowe",
      "tylko prawdopodobieństwo a priori zdarzeń",
      "wpływ jednego zdarzenia na inne"
    ],
    "correct": [
      "zmienne losowe"
    ]
  },
  {
    "question": "W sieci przekonań/Bayesa krawędzie reprezentują",
    "options": [
      "ciągłe zmienne losowe",
      "zmienne losowe (w tym dyskretne i ciągłe)",
      "wpływ jednego zdarzenia (zmiennej) na inne zdarzenie",
      "tylko prawdopodobieństwo a priori faktów"
    ],
    "correct": [
      "wpływ jednego zdarzenia (zmiennej) na inne zdarzenie"
    ]
  },
  {
    "question": "Założenie naiwne w klasyfikatorze bayesowskim mówi dokładnie, że",
    "options": [
      "zmienne wejściowe są parami zależne (bezwarunkowo)",
      "zmienne wejściowe są parami niezależne (bezwarunkowo)",
      "zmienne wejściowe są parami niezależne warunkowo w klasach decyzyjnych",
      "zmienne wejściowe są parami zależne warunkowo w klasach decyzyjnych"
    ],
    "correct": [
      "zmienne wejściowe są parami niezależne warunkowo w klasach decyzyjnych"
    ]
  },
  {
    "question": "Niech\n\n- t oznacza numer kroku uczenia sieci neuronowej,\n- e pewną przyjętą funkcję błędu (w szczególności może ona oznaczać błąd kwadratowy),\n- η, μ odpowiednio współczynniki uczenia i rozpędu.\n\nW metodzie uczenia z rozpędem wzór na poprawkę dowolnej wagi sieci, oznaczonej jako v ma postać",
    "options": [
      "v(t + 1) = v(t) - η (∂e / ∂v(t)) + μ(v(t) - v(t - 1))",
      "v(t + 1) - v(t) = - η (∂e / ∂v(t)) - μv(t)",
      "v(t + 1) = v(t) - η (∂e / ∂v(t)) - μ(v(t) - v(t - q))",
      "v(t + 1) = v(t) - η (∂e / ∂v(t)) + μv(t)"
    ],
    "correct": [
      "v(t + 1) = v(t) - η (∂e / ∂v(t)) + μ(v(t) - v(t - 1))"
    ]
  },
  {
    "question": "Realizacja zbioru Open (w algorytmach A* i Best-rst search) za pomocą kopca binarnego powoduje, że pobranie elementu minimalnego oraz włożenie nowego elementu są o złożonościach odpowiednio",
    "options": [
      "O(logn) i O(logn)",
      "O(1) i O(1)",
      "O(1) i O(logn)",
      "O(logn) i O(1)"
    ],
    "correct": [
      "O(logn) i O(logn)"
    ]
  },
  {
    "question": "Dla pewnego wektora cech x klasyfikator bayesowski zwraca odpowiedź y*, której probabilistyczny sens jest następujący",
    "options": [
      "y* = arg max P(X = x | Y = y)",
      "żadna z pozostałych odpowiedzi nie jest prawdziwa",
      "y* = arg max P(Y = y, X = x)",
      "y* = arg max P(Y = y | X = x)"
    ],
    "correct": [
      "y* = arg max P(Y = y | X = x)"
    ]
  },
  {
    "question": "Kod w języku programowania Prolog to zbiór",
    "options": [
      "zdań w rachunku zdań",
      "klauzul Horna, czyli takich, które zawierają więcej niż jeden niezanegowany predykat",
      "klauzul Horna, czyli takich, które zawierają co najwyżej jeden niezanegowany predykat",
      "dowolnych zdań w logice predykatów pierwszego rzędu"
    ],
    "correct": [
      "klauzul Horna, czyli takich, które zawierają co najwyżej jeden niezanegowany predykat"
    ]
  },
  {
    "question": "Niech η, μ oznaczają odpowiednio współczynniki uczenia i rozpędu. Jeżeli przez pewien czas w trakcie uczenia sieci neuronowej z rozpędem wielkości kolejnych gradientów pozostają w przybliżeniu stałe, to można powiedzieć, że efektywny współczynnik uczenia jest wówczas proporcjonalny do",
    "options": [
      "ημ",
      "η / (1 - μ)",
      "ημ^2",
      "μ / (1 - η)"
    ],
    "correct": [
      "η / (1 - μ)"
    ]
  },
  {
    "question": "Niech E_{l,k} oznacza wyrażenie błędu (obliczone w ramach metody wstecznej propagacji błędu) dla neuronu k-ego w warstwie l. Wtedy pochodna błędu kwadratowego ze względu na wagę v_{l,k,j} wynosi",
    "options": [
      "E_{l,k} φ_{l-1,j} (1 - φ_{l-1,j})",
      "√(E_{l,k} φ_{l-1,j} (1 - φ_{l-1,j}))",
      "√(E_{l,k} φ_{l-1,j})",
      "E_{l,k} φ_{l-1,j}"
    ],
    "correct": [
      "E_{l,k} φ_{l-1,j}"
    ]
  },
  {
    "question": "Modus ponendo ponens (Modus ponens) wyraża",
    "options": [
      "Jeżeli prawdziwe jest P ⇒ Q i P, to wnioskujemy prawdziwość Q",
      "Jeżeli prawdziwe jest P ⇒ Q i Q ⇒ R, to wnioskujemy prawdziwość R",
      "Jeżeli prawdziwe jest P ⇒ Q i ¬P, to wnioskujemy prawdziwość Q",
      "Jeżeli prawdziwe jest P ⇒ Q i ¬Q, to wnioskujemy prawdziwość P"
    ],
    "correct": [
      "Jeżeli prawdziwe jest P ⇒ Q i P, to wnioskujemy prawdziwość Q"
    ]
  },
  {
    "question": "Dla sieci MLP z jedną warstwą ukrytą, pochodne błędu kwadratowego dla wag v_{k,j} można wyrazić wzorem",
    "options": [
      "(y_{MLP} - y_i) w_k φ_k (1 - φ_k) x_{i,j}",
      "y_i φ_k (1 - φ_{hi}) x_{i,j}",
      "(y_{MLP} - y_i) φ_k (1 - φ_k) x_{i,j}",
      "y_i w_k φ_k (1 - φ_k) x_{i,j}"
    ],
    "correct": [
      "(y_{MLP} - y_i) w_k φ_k (1 - φ_k) x_{i,j}"
    ]
  },
  {
    "question": "Pewien algorytm genetyczny odnotował (dla populacji pięciu osobników) następujące przystosowania:\n\nf(x₁) = 5, f(x₂) = 1, f(x₃) = 10, f(x₄) = 2, f(x₅) = 2\n\n i będzie wykonywał selekcję ruletkową. Wskaż prawdziwe zdanie",
    "options": [
      "prawdopodobieństwo selekcji piątego osobnika wynosi 2/10",
      "osobnik drugi nie zostanie wyselekcjonowany",
      "oczekiwana liczba egzemplarzy trzeciego osobnika po selekcji wynosi 2.5",
      "oczekiwana liczba egzemplarzy pierwszego osobnika po selekcji wynosi 4/5"
    ],
    "correct": [
      "oczekiwana liczba egzemplarzy trzeciego osobnika po selekcji wynosi 2.5"
    ]
  },
  {
    "question": "Dana jest pewna struktura sieci bayesowskiej. Węzeł A i B nie mają rodziców i połączone są z węzłem C: A wpływa na C i B wpływa na C. Które z węzłów są niezależne, jeżeli nie podano żadnych dodatkowych przekonań (dowodów)?",
    "options": [
      "a nie ma węzłów niezależnych",
      "A i B",
      "C",
      "A, B, i C"
    ],
    "correct": [
      "A i B"
    ]
  },
  {
    "question": "W logice predykatów pierwszego rzędu podane jest zdanie:\n\n∀x wiedźmin(x) ⇒ mutant(x)\n\nJaki jest poprawny kod w Prologu wyrażający tę zależność?",
    "options": [
      "wiedzmin(x). mutant(x).",
      "wiedzmin(x) :- mutant(x).",
      "mutant(x) :- wiedzmin(x).",
      "wiedzmin(x), mutant(x)."
    ],
    "correct": [
      "mutant(x) :- wiedzmin(x)."
    ]
  },
  {
    "question": "Pochodna sigmoidalnej funkcji aktywacji wynosi",
    "options": [
      "exp(-s)/(1 + exp(-s))^2",
      "exp(s)/(1 + exp(-s))^2",
      "exp(-s)^2/(1 + exp(-s))",
      "exp(s)^2/(1 + exp(-s))"
    ],
    "correct": [
      "exp(-s)/(1 + exp(-s))^2"
    ]
  },
  {
    "question": "O naiwnym klasyfikatorze Bayesa można powiedzieć, że",
    "options": [
      "nie cierpi na przekleństwo wymiarowości i złożoność obliczenia odpowiedzi skaluje się kwadratowo wraz z liczbą zmiennych wejściowych",
      "cierpi na przekleństwo wymiarowości i złożoność obliczenia odpowiedzi skaluje się wykładniczo wraz z liczbą zmiennych wejściowych",
      "cierpi na przekleństwo wymiarowości i złożoność obliczenia odpowiedzi skaluje się liniowo wraz z liczbą zmiennych wejściowych",
      "nie cierpi na przekleństwo wymiarowości i złożoność obliczenia odpowiedzi skaluje się liniowo wraz z liczbą zmiennych wejściowych"
    ],
    "correct": [
      "nie cierpi na przekleństwo wymiarowości i złożoność obliczenia odpowiedzi skaluje się liniowo wraz z liczbą zmiennych wejściowych"
    ]
  },
  {
    "question": "Bezpieczeństwo numeryczne obliczeń w klasyfikatorze bayesowskim można podnieść poprzez",
    "options": [
      "poprawkę LaPlace'a",
      "założenie naiwne",
      "użycie funkcji gęstości",
      "logarytmowanie"
    ],
    "correct": [
      "logarytmowanie"
    ]
  },
  {
    "question": "Elementem gwarantującym znalezienie najkrótszej ścieżki (ścieżki o najmniejszym koszcie) przez algorytm A* jest",
    "options": [
      "heurystyka dopuszczalna",
      "użycie mapy mieszającej do implementacji zbioru Closed",
      "generowanie minimalnego zbioru potomków",
      "warunek stopu"
    ],
    "correct": [
      "heurystyka dopuszczalna"
    ]
  },
  {
    "question": "Zgodnie z dowodem twierdzenia Novikoa, górne ograniczenie na liczbę kroków wykonanych przez algorytm uczenia perceptronu prostego skaluje się odwrotnie proporcjonalnie do",
    "options": [
      "promienia danych",
      "kwadratu marginesu między klasami",
      "kwadratu promienia danych",
      "marginesu między klasami"
    ],
    "correct": [
      "kwadratu marginesu między klasami"
    ]
  },
  {
    "question": "W pewnym algorytmie genetycznym mają zostać skrzyżowane następujące dwa osobniki:\n\n(1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1)\n(1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0)\n\nw ramach krzyżowania jednopunktowego. Wskaż parę potomków, która nie jest możliwa do uzyskania niezależnie od wyboru punktu krzyżowania",
    "options": [
      "(1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0) , (1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1)",
      "(1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1) , (1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0)",
      "(1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0) , (1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1)",
      "(1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0) , (1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1)"
    ],
    "correct": [
      "(1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0) , (1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1)"
    ]
  },
  {
    "question": "Jeżeli zdarzenia dwa zdarzenia A, B są niezależne to",
    "options": [
      "P(A|B) = P(A)",
      "P(A ∩ B) > P(A) P(B)",
      "P(A|B) = P(A) P(B)",
      "żadna z pozostałych odpowiedzi nie jest prawdziwa"
    ],
    "correct": [
      "P(A|B) = P(A)"
    ]
  },
  {
    "question": "Unifikacja to",
    "options": [
      "Procedura wnioskowania z użyciem reguły modus ponens",
      "procedura/algorytm, w wyniku której uzyskuje się usunięcie wielkiego kwantyfikatora 'dla każdego'",
      "procedura/algorytm, w wyniku której uzyskuje się listę najbardziej ogólnych podstawień sprawiających, że dwa termy stają się równoważne",
      "procedura nazwana też skolemizacją zastępująca kwantyfikator mały 'istnieje'"
    ],
    "correct": [
      "procedura/algorytm, w wyniku której uzyskuje się listę najbardziej ogólnych podstawień sprawiających, że dwa termy stają się równoważne"
    ]
  },
  {
    "question": "Wzór na odpowiedź naiwnego klasyfikatora bayesowskiego można zapisać następująco",
    "options": [
      "y* = arg max ∏ P(X_j = x_j | Y = y) P(Y = y)",
      "y* = arg max ∏ P(Y = y | X_j = x_j) + P(Y = y)",
      "y* = arg max ∏ P(Y = y | X_j = x_j) P(Y = y)",
      "y* = arg max ∏ P(X_j = x_j | Y = y) + P(Y = y)"
    ],
    "correct": [
      "y* = arg max ∏ P(X_j = x_j | Y = y) P(Y = y)"
    ]
  },
  {
    "question": "Wskaż prawdziwe zdanie na temat metody uczenia RPROP dla sieci neuronowych",
    "options": [
      "zaniedbywany jest znak gradientu",
      "zaniedbywany jest współczynnik uczenia",
      "zaniedbywana jest wielkość gradientu",
      "żadna z pozostałych odpowiedzi nie jest prawdziwa"
    ],
    "correct": [
      "zaniedbywana jest wielkość gradientu"
    ]
  },
  {
    "question": "Algorytm rezolucji działa zgodnie z zasadą: Jeżeli baza wiedzy (teza) A1, A2,…, An jest niesprzeczna i prawdziwa, to",
    "options": [
      "formuła B jest wnioskiem z bazy wiedzy wtedy i tylko wtedy, gdy teza A1, A2,…, An, ¬B jest sprzeczna",
      "formuła B jest wnioskiem z bazy wiedzy wtedy i tylko wtedy, gdy teza A1, A2,…, An, ¬B jest sprzeczna",
      "formuła B jest wnioskiem z bazy wiedzy wtedy i tylko wtedy, gdy teza A1, A2,…, An, ¬B jest prawdziwa (niesprzeczna)",
      "formuła B jest wnioskiem z bazy wiedzy wtedy i tylko wtedy, gdy teza A1, A2,…, An, B jest sprzeczna"
    ],
    "correct": [
      "formuła B jest wnioskiem z bazy wiedzy wtedy i tylko wtedy, gdy teza A1, A2,…, An, ¬B jest sprzeczna"
    ]
  },
  {
    "question": "Przykładem zdania w logice predykatów pierwszego rzędu w koniunkcyjnej postaci normalnej (CNF) jest",
    "options": [
      "¬pompeian(x) roman(x)",
      "¬roman(x2) loyalt(x2, Caesar) hate(x2, Caesar)",
      "x (man(x) good(x))",
      "x roman(x) loyalt(x, Caesar) hate(x, Caesar)"
    ],
    "correct": [
      "¬roman(x2) loyalt(x2, Caesar) hate(x2, Caesar)"
    ]
  },
  {
    "question": "Dla pewnej gry dwuosobowej pojęcie „słaba sztuczna inteligencja” reprezentuje program",
    "options": [
      "nie wykorzystujący techniki quiescence",
      "wykorzystujący funkcję oceny pozycji zaprojektowaną przez człowieka",
      "wykorzystujący funkcję oceny pozycji wyuczoną lub wyewoluowaną przez algorytm",
      "wykorzystujący technikę quiescence"
    ],
    "correct": [
      "wykorzystujący funkcję oceny pozycji zaprojektowaną przez człowieka"
    ]
  },
  {
    "question": "Liczba iteracji, którą musiałby wykonać algorytm wyczerpujący dla „dyskretnego problemu plecakowego” wynosi:",
    "options": [
      "n",
      "Ackermann(n)",
      "n!",
      "2^n"
    ],
    "correct": [
      "2^n"
    ]
  },
  {
    "question": "Według Minsky’ego maszyna zdolna do 100% introspekcji",
    "options": [
      "dojdzie do przeświadczenia, że jest tylko maszyną",
      "rozwiąże dowolny problem w czasie wielomianowym",
      "osiągnie nadludzką inteligencję",
      "zda test Turinga"
    ],
    "correct": [
      "dojdzie do przeświadczenia, że jest tylko maszyną"
    ]
  },
  {
    "question": "Jeżeli dla problemu komiwojażera i algorytmu przeszukującego, stan zdefiniujemy jako: zbiór odwiedzonych wierzchołków oraz informację, w którym z nich aktualnie przebywamy; to dobrą dopuszczalną heurystykę może stanowić (wybierz najlepszą możliwość)",
    "options": [
      "odległość do najdalszego nieodwiedzonego wierzchołka",
      "długość brzegu powłoki wypukłej pozostałych wierzchołków",
      "długość minimalnego drzewa rozpinającego pozostałych wierzchołków",
      "odległość do najbliższego nieodwiedzonego wierzchołka"
    ],
    "correct": [
      "długość minimalnego drzewa rozpinającego pozostałych wierzchołków"
    ]
  },
  {
    "question": "Algorytm Dijkstry wybierając kolejne stany do odwiedzenia kieruje się",
    "options": [
      "tylko kosztem pozostałym od danego stanu do celu",
      "sumą kosztu przebytego i pozostałego",
      "tylko kosztem przebytym do chwili osiągnięcia stanu",
      "żadne z powyższych"
    ],
    "correct": [
      "tylko kosztem przebytym do chwili osiągnięcia stanu"
    ]
  },
  {
    "question": "Dla algorytmu przycinanie α-β równanie rekurencyjne opisujące minimalną liczbę liści w drzewie o wysokości d, które trzeba odwiedzić (w przypadku optymistycznym) aby poznać dokładną wartość stanu ma postać",
    "options": [
      "Rd = ∑(k=0 do d-1) Rk + b",
      "Rd = Rd-1 + (b - 1) Rd-2",
      "Rd = 2Rd/2 + bd",
      "Rd = (b - 1) Rd-1"
    ],
    "correct": [
      "Rd = Rd-1 + (b - 1) Rd-2"
    ]
  },
  {
    "question": "W przycinaniu alfa-beta badany jest pewien stan typu MIN, dla którego procedurę wywołano z początkowymi wartościami α = -8, β = 2. Przypuśćmy, że wartości zwracane do tego stanu ze stanów potomnych wynosiłyby kolejno: -1, -9, ∞, -∞. Przycięcie nastąpi po:",
    "options": [
      "trzecim potomku",
      "czwartym potomku",
      "pierwszym potomku",
      "drugim potomku"
    ],
    "correct": [
      "drugim potomku"
    ]
  },
  {
    "question": "Funkcja oceny pozycji dla szachów zaproponowana przez C. Shannona (1949) zawierała",
    "options": [
      "składniki materialne i pozycyjne",
      "składniki, których wagi były nastrajane algorytmem genetycznym",
      "tylko składniki materialne",
      "tylko składniki pozycyjne"
    ],
    "correct": [
      "składniki materialne i pozycyjne"
    ]
  },
  {
    "question": "W procedurze oceniającej stan typu MAX w ramach przycinania α-β:",
    "options": [
      "aktualizacjom podlegają obydwie wartości α i β",
      "ani α, ani β nie zmieniają się",
      "aktualizacjom podlega tylko wartość α",
      "aktualizacjom podlega tylko wartość β"
    ],
    "correct": [
      "aktualizacjom podlega tylko wartość α"
    ]
  },
  {
    "question": "Dla układanki puzzle przesuwne postaci (cyfry pisane kolejno wierszami): (1, 8, 2; 0, 4, 3; 7, 6, 5) liczba konfliktów liniowych wynosi",
    "options": [
      "5",
      "6",
      "0",
      "2"
    ],
    "correct": [
      "2"
    ]
  },
  {
    "question": "Elementem gwarantującym znalezienie najkrótszej ścieżki (ścieżki o najmniejszym koszcie) przez algorytm A* jest",
    "options": [
      "heurystyka dopuszczalna",
      "użycie tablicy mieszającej do implementacji zbioru closed",
      "warunek stopu",
      "generowanie minimalnego zbioru potomków"
    ],
    "correct": [
      "heurystyka dopuszczalna"
    ]
  },
  {
    "question": "Algorytm IDA*",
    "options": [
      "nie gwarantuje on znalezienia najkrótszej ścieżki",
      "nie wymaga on zbioru Closed",
      "jest on wolniejszy niż algorytm Dijkstry",
      "przechowuje ewidencję odwiedzonych stanów"
    ],
    "correct": [
      "przechowuje ewidencję odwiedzonych stanów"
    ]
  },
  {
    "question": "Niech h1 i h2 oznaczają dwie dopuszczalne funkcje heurystyczne dla pewnego problemu przeszukiwania grafu. Jeżeli h1 ma wartości większe niż lub równe h2, tzn. ∀s, h1(s) ≥ h2(s), to algorytm A* wyposażony w h1 będzie przeciętnie",
    "options": [
      "błądził mniej niż A* wyposażony w h2",
      "błądził więcej niż A* wyposażony w h2",
      "wymagał większego zbioru Open",
      "wymagał mniejszego zbioru Open"
    ],
    "correct": [
      "błądził mniej niż A* wyposażony w h2"
    ]
  },
  {
    "question": "W perceptronie prostym aktualny wektor wag wynosi (6, -2, -1, 3). Do poprawki wybrano przykład x1 = (1, 3, 5, 1). Oznacza to, że:",
    "options": [
      "etykieta klasy tego przykładu to yi = 1",
      "etykieta klasy tego przykładu to yi = -1",
      "ustalenie etykiety nie jest możliwe",
      "ustalenie etykiety klasy zależy od współczynnika uczenia"
    ],
    "correct": [
      "etykieta klasy tego przykładu to yi = 1"
    ]
  },
  {
    "question": "Wybierz nieprawdziwe zdanie o sigmoidalnej funkcji aktywacji neuronu:",
    "options": [
      "ma punkt przegięcia w punkcie (0, 1/2)",
      "przyjmuje wartości z przedziału (-1, 1)",
      "jest wszędzie różniczkowalna",
      "jest ściśle rosnąca"
    ],
    "correct": [
      "jest ściśle rosnąca"
    ]
  },
  {
    "question": "Zgodnie z dowodem twierdzenia Novikoffa, górne ograniczenie na liczbę kroków wykonanych przez algorytm uczenia perceptronu prostego skaluje się proporcjonalnie do",
    "options": [
      "marginesu między klasami",
      "kwadratu marginesu między klasami",
      "promienia danych",
      "kwadratu promienia danych"
    ],
    "correct": [
      "kwadratu promienia danych"
    ]
  },
  {
    "question": "Wskaż wartość funkcji ReLU i wartość jej pochodnej (w tej kolejności) w punkcie s = 2.",
    "options": [
      "2, 1",
      "2e^1, 0",
      "e^-2, e^2",
      "1/(1 + e^-2), 2(1 - 2)"
    ],
    "correct": [
      "2, 1"
    ]
  },
  {
    "question": "Wzór, wg którego naiwny klasyfikator Bayesa (dla zmiennych dyskretnych), oblicza odpowiedź dla wejściowego wektora (x1, ..., xn) może być zapisany w postaci",
    "options": [
      "arg maxy -(log P(Y = y) + ∑(j=1 do n) log P(Xj = xj|Y = y))",
      "arg maxy (∑(j=1 do n) log P(Xj = xj) + log P(Y = y))",
      "arg maxy P(Y = y) ∏(j=1 do n) P(Xj = xj|Y = y)",
      "arg maxy ∏(j=1 do n) P(Xj = xj) P(Y = y)"
    ],
    "correct": [
      "arg maxy P(Y = y) ∏(j=1 do n) P(Xj = xj|Y = y)"
    ]
  },
  {
    "question": "Niech m, n, K oznaczają kolejno liczbę: przykładów uczących, cech (zmiennych dyskretnych), klas. Uczenie naiwnego klasyfikatora Bayesa można zrealizować w czasie proporcjonalnym do:",
    "options": [
      "K ⋅ m ⋅ n",
      "m ⋅ n",
      "K ⋅ n",
      "K ⋅ m"
    ],
    "correct": [
      "m ⋅ n"
    ]
  },
  {
    "question": "Dla klasyfikatorów bayesowskich, który z poniższych elementów zapewnia bezpieczeństwo obliczeń prowadzonych na pewnym typie zmiennoprzecinkowym",
    "options": [
      "logarytmowanie",
      "dyskretyzacja",
      "założenie naiwne",
      "poprawka Laplace’a"
    ],
    "correct": [
      "logarytmowanie"
    ]
  },
  {
    "question": "Wyraz P(dane|model) w tzw. regule Bayesa jest określany jako",
    "options": [
      "prawdopodobieństwo całkowite",
      "likelihood",
      "prawdopodobieństwo a priori",
      "prawdopodobieństwo a posteriori"
    ],
    "correct": [
      "likelihood"
    ]
  },
  {
    "question": "Podczas obliczeń wstecz dla l-tej warstwy sieci MLP, na podstawie macierzy δl o wymiarach b × M chcemy wykonać propagację błędów wstecz, otrzymując macierz δl-1 o wymiarach b × N. Wzór tej operacji ma postać:",
    "options": [
      "φ'(Sl-1) ∘ (δl Wl)",
      "φ'(Sl-1) ∘ (δl^T Wl)",
      "φ'(Sl-1) ∘ (δl Wl^T)",
      "φ'(Sl-1) ∘ (δl^T Wl^T)"
    ],
    "correct": [
      "φ'(Sl-1) ∘ (δl Wl^T)"
    ]
  },
  {
    "question": "Dla l-tej warstwy sieci MLP wyznacz gradient ∇Vl, jeżeli δl = [[1, 2], [3, 4]] a Xl = [[2, -2], [-5, 3]].",
    "options": [
      "[[-2, 1], [-2, -3]]",
      "[[-8, 4], [-14, 6]]",
      "[[-13, 7], [-16, 8]]",
      "[[-4, 4], [-4, 2]]"
    ],
    "correct": [
      "[[-8, 4], [-14, 6]]"
    ]
  },
  {
    "question": "W obliczanej przez algorytm RMSProp poprawce dla wag postaci: -η ∇l / √v + ε, wyraz v_t reprezentuje",
    "options": [
      "rozpędzany współczynnik uczenia",
      "wygaszany współczynnik uczenia",
      "wykładnicza średnia krocząca gradientów",
      "wykładnicza średnia krocząca kwadratów gradientów"
    ],
    "correct": [
      "wykładnicza średnia krocząca kwadratów gradientów"
    ]
  },
  {
    "question": "Zakładając, że dla danego numeru kroku uczenia t uaktualniono już wyrażenia m_t i v_t, reprezentujące odpowiednio pierwszy i drugi moment gradientu, wskaż wzór na poprawkę wag sieci neuronowej zgodną z algorytmem Adam:",
    "options": [
      "-η * (m_t / (1 - β_1^{t+1})) / (√(v_t^2 / (1 - β_2^{t+1})) + ε)",
      "-η * (m_t / (1 + β_1^{t+1})) / (√(v_t^2 / (1 + β_2^{t+1})) + ε)",
      "-η * (m_t / (1 - β_1^{t+1})) / (√(v_t / (1 - β_2^{t+1})) + ε)",
      "-η * (m_t / (1 + β_1^{t+1})) / (√(v_t / (1 + β_2^{t+1})) + ε)"
    ],
    "correct": [
      "-η * (m_t / (1 - β_1^{t+1})) / (√(v_t / (1 - β_2^{t+1})) + ε)"
    ]
  },
  {
    "question": "W selekcji ruletkowej algorytmu genetycznego pewien osobnik x ma przystosowanie f(x) = 20, a suma przystosowań wszystkich osobników w populacji wynosi 80. Wiedząc, że populacja składa się z 10 osobników, oblicz oczekiwaną liczbę egzemplarzy tego osobnika w następnym pokoleniu:",
    "options": [
      "8/4",
      "2.5",
      "4/20",
      "0.5"
    ],
    "correct": [
      "2.5"
    ]
  },
  {
    "question": "Wymiana kawałków informacji „genetycznej” pomiędzy osobnikami zachodzi podczas operacji:",
    "options": [
      "selekcji elitarnej",
      "selekcji turniejowej",
      "krzyżowania",
      "mutacji"
    ],
    "correct": [
      "krzyżowania"
    ]
  },
  {
    "question": "W sieci neuronowej MLP z jedną warstwą ukrytą – o wagach (w_kj) dla warstwy ukrytej oraz wagach (v_k) dla warstwy wyjściowej – użyto sigmoidalnej funkcji aktywacji φ i kwadratowej funkcji straty: (y_MLP - y_i)^2. Pochodne tej funkcji straty ze względu na wagi w_kj można wyrazić wzorami:",
    "options": [
      "2(y_MLP - y_i) * w_kj φ_k (1 - φ_k) x_j",
      "2(y_MLP - y_i) * w_kj φ_k (1 - φ_k) x_k",
      "2(y_MLP - y_i) * v_j φ_k (1 - φ_k) x_k",
      "2(y_MLP - y_i) * w_kj φ_k (1 - φ_k) x_j"
    ],
    "correct": [
      "2(y_MLP - y_i) * w_kj φ_k (1 - φ_k) x_j"
    ]
  },
  {
    "question": "Dla sieci neuronowej z powyższego zadania obliczono pochodną funkcji straty ze względu na wagę v_0 (wyraz wolny w warstwie wyjściowej). Pochodna ta wynosi:",
    "options": [
      "2(y_MLP - y_i) s_0",
      "2(y_MLP - y_i)",
      "2(y_MLP - y_i) v_0",
      "2(y_MLP - y_i) w_0,0"
    ],
    "correct": [
      "2(y_MLP - y_i) s_0"
    ]
  },
  {
    "question": "Reguła łańcuchowa w ramach wstecznej propagacji błędu w sieci neuronowej powoduje, że pochodne cząstkowe",
    "options": [
      "wygaszają się do zera",
      "nie zależą od funkcji aktywacji neuronu",
      "wzdłuż jednej ścieżki połączeń są mnożone",
      "dla ścieżek alternatywnych są sumowane"
    ],
    "correct": [
      "wzdłuż jednej ścieżki połączeń są mnożone"
    ]
  },
  {
    "question": "Niech δ_{l,j} oznacza wyrażenie błędu (obliczane w ramach metody wstecznej propagacji błędu) dla neuronu nr j w warstwie nr l sieci MLP. Wzór pozwalający na obliczenie tego wyrażenia na podstawie wyrażeń błędu obliczonych wcześniej ma postać:",
    "options": [
      "∂s_{l,j} / ∂φ_{l,j} ∑_{k=1}^{N_{l-1}} w_{l-1,k,j} δ_{l-1,k}",
      "∂φ_{l,j} / ∂s_{l,j} ∑_{k=1}^{N_{l-1}} w_{l-1,k,j} δ_{l-1,k}",
      "∂s_{l,j} / ∂φ_{l,j} ∑_{k=1}^{N_{l+1}} w_{l+1,k,j} δ_{l+1,k}",
      "∂φ_{l,j} / ∂s_{l,j} ∑_{k=1}^{N_{l+1}} w_{l+1,k,j} δ_{l+1,k}"
    ],
    "correct": [
      "∂φ_{l,j} / ∂s_{l,j} ∑_{k=1}^{N_{l+1}} w_{l+1,k,j} δ_{l+1,k}"
    ]
  },
  {
    "question": "Podczas obliczeń w przód w sieci MLP na wejście l-tej warstwy (o N wejściach i M wyjściach) podano macierz X_l o wymiarach b × N, gdzie b to rozmiar wsadu (mini-batch). Niech W_l oznacza macierz wag tej warstwy zaś W_{l;0} wektor kolumnowy wyrazów wolnych. Wzór obliczający dla tej warstwy macierz sum ważonych – S_l (o wymiarach b × M) – ma postać:",
    "options": [
      "W_l X_l + W_{l;0}^T 1_{1×b}",
      "(W_l X_l + W_{l;0}^T) 1_{1×b}",
      "W_l X_l^T + W_{l;0} 1_{1×b}",
      "(W_l X_l^T + W_{l;0} 1_{1×b})^T"
    ],
    "correct": [
      "(W_l X_l + W_{l;0}^T) 1_{1×b}"
    ]
  },
  {
    "question": "Dokładność to właściwość systemu reprezentacji wiedzy mówiąca o możliwości:",
    "options": [
      "wnioskowania w ogóle",
      "uzyskiwania rzeczywistych konceptów z wnioskowania",
      "manipulowania konceptami w sposób dowolny",
      "wyrażenia w systemie każdego rzeczywistego konceptu"
    ],
    "correct": [
      "wyrażenia w systemie każdego rzeczywistego konceptu"
    ]
  },
  {
    "question": "Które ze zdań najlepiej opisuje założenie o zamkniętym świecie (Closed World Assumption) w programowaniu logicznym?",
    "options": [
      "Zdania atomowe, o których nie wiemy, że są prawdziwe, uważa się za fałszywe.",
      "Zmienne spod kwantyfikatorów w formule mogą być zastąpione dowolną stałą.",
      "Żaden model nie zawiera innych niż te wykorzystane w postaci systemu obiektów.",
      "Różne stałe odnoszą się do różnych obiektów rzeczywistych."
    ],
    "correct": [
      "Zdania atomowe, o których nie wiemy, że są prawdziwe, uważa się za fałszywe."
    ]
  },
  {
    "question": "Które z poniższych wyrażeń jest poprawnie sformułowanym wyrażeniem w logice predykatów?",
    "options": [
      "∀x ⇒ P(x,y) ∨ R(z)",
      "∀x (P(x) ∧ ∃y Q(y))",
      "∃x (P(x) ∨ ∀Q(y))",
      "P(x,y) ∧ ∀z(Q(z) ∨ R)"
    ],
    "correct": [
      "∀x (P(x) ∧ ∃y Q(y))"
    ]
  },
  {
    "question": "Które z wyrażeń w logice predykatów najlepiej wyraża wiedzę ze zdania 'Studenci spędzają czas na nauce bądź relaksie'?",
    "options": [
      "∀x (Uczysie(x) ∨ Relaksuje(x))",
      "∃x (Student(x) → Uczysie(x) ∨ Relaksuje(x))",
      "∀x (Student(x) ∧ Uczysie(x) → Relaksuje(x))",
      "∀x (Student(x) → Uczysie(x) ∨ Relaksuje(x))"
    ],
    "correct": [
      "∀x (Student(x) → Uczysie(x) ∨ Relaksuje(x))"
    ]
  },
  {
    "question": "Unifikacja to procedura/algorytm, który:",
    "options": [
      "z bazy zdań prawdziwych wyprowadza wnioski o prawdziwej hipotezie przez substytucje",
      "prowadzi do substytucji kwantyfikatora ogólnego na kwantyfikator egzystencjalny",
      "podaje listę warunków, które trzeba spełnić, by dwa predykaty zostały zastąpione",
      "zwraca listę najbardziej ogólnych podstawień sprawiających, że dwa termy stają się równoważne"
    ],
    "correct": [
      "zwraca listę najbardziej ogólnych podstawień sprawiających, że dwa termy stają się równoważne"
    ]
  },
  {
    "question": "Jakie są podstawowe różnice między łańcuchowaniem regresywnym (LR) i łańcuchowaniem progresywnym (LP)?",
    "options": [
      "LR wykorzystuje podejście oddolne, zaczynając od konkretnych faktów i przechodząc do ogólnych reguł, podczas gdy LP podejście ogórne, zaczynając od ogólnych reguł i przechodząc do faktów.",
      "LR to metoda, w której system generuje nowe dane w oparciu o istniejące reguły, podczas gdy LP modyfikuje istniejące reguły w oparciu o nowe dane.",
      "LR zaczyna się od możliwych wniosków/hipotez, aby znaleźć nowe dowody/fakty, podczas gdy LP zaczyna się od dowodów/faktów i wykorzystuje reguły, aby dojść do wniosków/hipotez.",
      "LR jest głównie wykorzystywany do generowania reguł, podczas gdy LP jest wykorzystywany do generowania faktów."
    ],
    "correct": [
      "LR wykorzystuje podejście oddolne, zaczynając od konkretnych faktów i przechodząc do ogólnych reguł, podczas gdy LP podejście ogórne, zaczynając od ogólnych reguł i przechodząc do faktów."
    ]
  },
  {
    "question": "Przykładem zdania w logice predykatów pierwszego rzędu w koniunkcyjnej postaci normalnej (klauzulowej) jest:",
    "options": [
      "∃x (Czlowiek(x) ∧ Dobry(x))",
      "¬Z_pompeii(y) ∨ Rzymianin(y)",
      "{ A ∧ (B ∧ C) } ↔ { (A ∧ B) ∧ C }",
      "{ Czlowiek(z) → Lubi(z, Ptaki) ∨ Nienawidzi(z, Ptaki) }"
    ],
    "correct": [
      "¬Z_pompeii(y) ∨ Rzymianin(y)"
    ]
  },
  {
    "question": "Algorytm rezolucji działa zgodnie z zasadą: jeżeli baza wiedzy składająca się z aksjomatów A jest niesprzeczna i prawdziwa, to:",
    "options": [
      "formuła B jest wnioskiem z bazy wiedzy wtedy i tylko wtedy, gdy A ∧ ¬B jest niespełnialna",
      "formuła B jest wnioskiem z bazy wiedzy wtedy i tylko wtedy, gdy A ∧ B jest niespełnialna",
      "formuła B jest wnioskiem z bazy wiedzy wtedy i tylko wtedy, gdy A ∧ ¬B jest spełnialna",
      "formuła ¬B jest wnioskiem z bazy wiedzy wtedy i tylko wtedy, gdy A ∧ ¬B jest niespełnialna"
    ],
    "correct": [
      "formuła B jest wnioskiem z bazy wiedzy wtedy i tylko wtedy, gdy A ∧ ¬B jest niespełnialna"
    ]
  },
  {
    "question": "Które ze stwierdzeń najdokładniej opisuje, czym jest kod w języku programowania Prolog?",
    "options": [
      "zbiór wyrażeń w logice predykatów pierwszego rzędu",
      "zbiór klauzul Horna z głową (każda z jednym pozytywnym predykatem)",
      "zbiór klauzul Horna bez głowy (każda bez pozytywnego predykatu)",
      "zbiór dowolnych klauzul w logice predykatów pierwszego rzędu"
    ],
    "correct": [
      "zbiór klauzul Horna z głową (każda z jednym pozytywnym predykatem)"
    ]
  },
  {
    "question": "W logice predykatów pierwszego rzędu podane jest zdanie ∀x(Czlowiek(x) ∧ Prawo_jazdy(x) → Kierowca(x)). Jaki jest poprawny kod w Prologu wyrażający tę zależność?",
    "options": [
      "kierowca(X) :- prawo_jazdy(X), czlowiek(X).",
      "czlowiek(X) :- prawo_jazdy(X), kierowca(X).",
      "prawo_jazdy(x). kierowca(x) . kierowca(x).",
      "prawo_jazdy(X), czlowiek(X) :- kierowca(X)."
    ],
    "correct": [
      "kierowca(X) :- prawo_jazdy(X), czlowiek(X)."
    ]
  }
]